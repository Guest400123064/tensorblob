<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 16.0.0"/>
    <title>tensorblob API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#292929;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:27px;vertical-align:bottom;width:50px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>


            <h2>Contents</h2>
            <ul>
  <li><a href="#tensorblob">tensorblob</a>
  <ul>
    <li><a href="#features">Features</a></li>
    <li><a href="#installation">Installation</a></li>
    <li><a href="#core-use-cases">Core Use Cases</a></li>
    <li><a href="#performance-and-scalability">Performance and Scalability</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
  </ul></li>
</ul>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#TensorBlob">TensorBlob</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#TensorBlob.__init__">TensorBlob</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.status_name">status_name</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.config_name">config_name</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.ignore_for_config">ignore_for_config</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.open">open</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.unlink">unlink</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.apply_param_hooks">apply_param_hooks</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.filename">filename</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.dtype">dtype</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.shape">shape</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.block_size">block_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.mode">mode</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.max_cached_blocks">max_cached_blocks</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.configpath">configpath</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.statuspath">statuspath</a>
                        </li>
                        <li>
                                <a class="variable" href="#TensorBlob.closed">closed</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.tell">tell</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.seek">seek</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.close">close</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.flush">flush</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.read">read</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.write">write</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.truncate">truncate</a>
                        </li>
                        <li>
                                <a class="function" href="#TensorBlob.extend">extend</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22160%22%20viewBox%3D%220%200%20150%2080%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M132.316%2048.886c.276-4.679%202.342-6.698%204.409-7.982s4.27-1.165%206.751-1.055c1.586.07%203.044.156%204.222-.482%201.142-.619%202.026-1.932%202.162-3.739.268-3.576-1.929-5.368-5.006-5.551s-7.599.524-10.517%201.606c-4.455%201.652-8.588%206.606-9.552%208.992s-2.342%206.193-1.745%2010.873%202.664%209.221%205.878%2011.79%205.878%203.808%2010.103%204.312%203.444.229%206.062.229%205.006-2.202%204.914-4.909-2.296-5.001-4.501-4.863-3.077.505-5.281.229-7.715-2.064-7.899-9.451z%22%20fill%3D%22%23198754%22/%3E%3Ccircle%20cx%3D%22101.504%22%20cy%3D%2248.943%22%20r%3D%2214.208%22%20fill%3D%22none%22%20stroke%3D%22%23198754%22%20stroke-width%3D%229.354%22/%3E%3Cpath%20d%3D%22M87.81.002c-3.637.065-5.001.454-7.014%201.232s-3.443%201.363-6.3%204.282c-1.723%201.76-3.148%205.019-3.776%207.329-.413%201.521-.316%202.63-.316%202.63l-.195%2034.612c.065%205.774-6.755%208.305-9.612%208.37s-9.678-1.038-9.743-9.408%207.128-9.521%208.362-9.521c1.413-.13%202.526-.021%203.718-.016%202.071.009%204.157-.778%204.092-4.671s-4.157-4.736-4.157-4.736c-6.3-.843-11.43%202.206-11.43%202.206S40.917%2038.15%2041.372%2049.634%2051.568%2068.19%2061.311%2068.125s18.316-7.007%2018.445-17.193l.13-22.772c.046-2.291%202.683-3.644%204.476-4.203.745-.232%201.694-.274%201.694-.274l10.457-.13s4.871-.324%207.729-3.114%204.352-6.294%204.352-6.294.974-3.049.13-4.606-.195-1.233-2.792-3.309-8.573-4.477-8.573-4.477S91.447-.063%2087.81.002zM0%2047.169l.065%2028.417S0%2080.127%204.481%2079.997s5.072-3.866%205.049-4.152l-.113-28.482s1.624-7.656%209.937-7.721%2010.002%206.942%2010.002%208.499-.909%2010.51-9.093%2010.51c-.948%200-2.99-.567-4.145-.272-3.919%201-3.194%204.554-3.194%204.554s.065%205.061%207.404%204.996%2018.575-6.034%2018.575-19.074S26.953%2030.04%2019.549%2029.91%201.234%2035.296%200%2047.169z%22%20fill%3D%22%23198754%22/%3E%3Cg%20transform%3D%22matrix%28.325601%200%200%20.325256%20-10.32669%20-45.802786%29%22%3E%3Ccircle%20cx%3D%22297.554%22%20cy%3D%22172.286%22%20r%3D%2216.5%22%20fill%3D%22%23fff%22/%3E%3Cellipse%20cx%3D%22297.709%22%20cy%3D%22172.642%22%20rx%3D%2211.071%22%20ry%3D%2210.871%22%20fill%3D%22%23105a48%22/%3E%3Ccircle%20cx%3D%22304.104%22%20cy%3D%22167.667%22%20r%3D%224.5%22%20fill%3D%22%23fff%22/%3E%3C/g%3E%3Cpath%20d%3D%22M94.661%2017.032l.893-1.476s.99.714%201.916.925%201.575.114%202.955.114l14.565-.162c1.283-.032%203.085-.762%203.02-3.293s-.373-3.503-.373-3.503l1.283-.487s.52.503.877%201.573.309%201.995.292%202.66-.227%201.541-.227%201.541%201.564-.308%202.359-1.038.823-.779%201.489-1.508.812-.86.812-.86.552-.13.877.26.341.957.065%201.46-1.672%202.206-3.247%203.066-2.76%201.427-3.929%201.768-3.848.73-7.063.714l-10.944-.114s-2.143-.081-3.02-.373-2.241-.973-2.598-1.265z%22%20fill%3D%22%23d36d49%22/%3E%3Cg%20fill%3D%22%23105a48%22%3E%3Cellipse%20cx%3D%2293.052%22%20cy%3D%2243.567%22%20rx%3D%22.869%22%20ry%3D%221.014%22%20transform%3D%22rotate%28341.022%29%22/%3E%3Cellipse%20cx%3D%22104.3%22%20cy%3D%22-16.184%22%20rx%3D%22.865%22%20ry%3D%221.009%22%20transform%3D%22rotate%2814.786%29%22/%3E%3C/g%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
tensorblob    </h1>

                        <div class="docstring"><p><a href="https://www.python.org/downloads/release/python-3100/"><img src="https://img.shields.io/badge/python-%203.10%20|%203.11%20|%203.12-blue.svg" alt="Python 3.10" /></a>
<a href="https://opensource.org/licenses/Apache-2.0"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License: Apache 2.0" /></a>
<a href="https://github.com/Guest400123064/tensorblob/actions/workflows/test.yaml"><img src="https://github.com/Guest400123064/tensorblob/actions/workflows/test.yaml/badge.svg" alt="test" /></a>
<a href="https://codecov.io/gh/Guest400123064/tensorblob"><img src="https://codecov.io/gh/Guest400123064/tensorblob/branch/main/graph/badge.svg?token=K00BM34OCO" alt="codecov" /></a>
<a href="https://pypi.org/project/tensorblob/"><img src="https://img.shields.io/pypi/v/tensorblob" alt="PyPI" /></a></p>

<h1 id="tensorblob">tensorblob</h1>

<p>A lightweight, dynamic-sized, memory-mapped tensor storage with file-like APIs, while also supporting integer indexing and slicing, built with <code>MemoryMappedTensor</code> from <a href="https://github.com/pytorch/tensordict"><code>tensordict</code></a>.</p>

<h2 id="features">Features</h2>

<ul>
<li>ðŸ”— <strong>Memory-mapped storage</strong>: Efficient storage of large collections of same-shaped tensors</li>
<li>ðŸ’¾ <strong>File-like APIs</strong>: Read, write, and seek like a file, while also supporting integer indexing and slicing</li>
<li>âš¡ <strong>Dynamic-sized</strong>: No need to specify the total number of tensors upfront</li>
<li>ðŸ”„ <strong>Extend and truncate</strong>: Extend the blob with another blob or truncate the blob to a specific position</li>
<li>ðŸš€ <strong>LRU cache</strong>: Automatic management of memory-mapped blocks for scalability with large blobs</li>
</ul>

<h2 id="installation">Installation</h2>

<p>From PyPI:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>tensorblob
</code></pre>
</div>

<p>If you are interested in the experimental (i.e., unstable and undertested) version, you can install it from GitHub:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/Guest400123064/tensorblob.git
</code></pre>
</div>

<h2 id="core-use-cases">Core Use Cases</h2>

<h3 id="quick-start">Quick Start</h3>

<p>The example below shows how to create a new storage for a collection of randomly generated fake embeddings, and how to access them by index. Since the storage is memory-mapped, no need to read all tensors into memory; just access them by index.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorblob</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorBlob</span>

<span class="c1"># Create a new storage for a collection of randomly generated fake embeddings;</span>
<span class="c1"># need to specify the data type and shape of each tensor for creation</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;embeddings.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span><span class="si">}</span><span class="s2"> embeddings&quot;</span><span class="p">)</span>

<span class="c1"># No need to specify the configurations again after creation</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;embeddings.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">e1</span> <span class="o">=</span> <span class="n">blob</span><span class="p">[</span><span class="mi">42</span><span class="p">]</span>
    <span class="n">e2</span> <span class="o">=</span> <span class="n">blob</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">16384</span><span class="p">:</span><span class="o">-</span><span class="mi">12345</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Similarity: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">e1</span><span class="p">,</span><span class="w"> </span><span class="n">e2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="processing-large-datasets">Processing Large Datasets</h3>

<p>Store and preprocess datasets larger than RAM using memory mapping can be useful to accelerate the training process by reducing the time spent on data loading and transformation.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/images.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">image_batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image_batch</span><span class="p">))</span>

<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/images.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">blob</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="incremental-data-collection">Incremental Data Collection</h3>

<p>Append new data to existing blobs can be useful with streaming data collection.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;positions.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">initial_position</span><span class="p">)</span>

<span class="c1"># Later: append more data by opening the blob in append mode</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;positions.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">trajectory_queue</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
        <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total trajectory recorded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="random-access-and-updates-with-file-like-apis">Random Access and Updates with File-Like APIs</h3>

<p>Read and modify specific tensors starting from a specific position.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">io</span>

<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/features.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current position: </span><span class="si">{</span><span class="n">blob</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">blob</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Read </span><span class="si">{</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> tensors&quot;</span><span class="p">)</span>

    <span class="c1"># Update specific positions, whence is also supported</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="o">-</span><span class="mi">500</span><span class="p">,</span> <span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">updated_features</span><span class="p">)</span>

    <span class="c1"># Append new data</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">))</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">additional_features</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="extend-and-truncate">Extend and Truncate</h3>

<p>Extend the blob with another blob or truncate the blob to a specific position. Extension could be useful if we want to merge two blobs into one, e.g., results from two different processes. Note that extension operation does not delete the original data.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/features.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">other_blob</span><span class="p">)</span>

<span class="c1"># Extension without maintaining the order is faster</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/features.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">other_blob</span><span class="p">,</span> <span class="n">maintain_order</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/features.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="n">blob</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Truncated to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span><span class="si">}</span><span class="s2"> tensors&quot;</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="performance-and-scalability">Performance and Scalability</h2>

<h3 id="memory-management">Memory Management</h3>

<p>TensorBlob uses an LRU (Least Recently Used) cache to manage memory-mapped blocks efficiently. This allows you to work with blobs containing millions of tensors without loading everything into memory.</p>

<p><strong>Default behavior:</strong></p>

<ul>
<li>Automatically caches up to ~4,000 blocks (1/16 of system's VMA limit)</li>
<li>Blocks loaded on-demand when accessed</li>
<li>Least recently used blocks automatically evicted when cache is full</li>
</ul>

<p><strong>For large-scale workloads:</strong></p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="c1"># Increase cache for better random access performance</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;large.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">max_cached_blocks</span><span class="o">=</span><span class="mi">10_000</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">random_indices</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">blob</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Cached blocks reused efficiently</span>

<span class="c1"># Decrease cache for memory-constrained environments</span>
<span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data.blob&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">max_cached_blocks</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">blob</span><span class="p">:</span>  <span class="c1"># Sequential access works fine with small cache</span>
        <span class="n">process</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>Performance tips:</strong></p>

<ul>
<li>Sequential access patterns work well with any cache size</li>
<li>Random access benefits from larger cache sizes</li>
<li>Each cached block consumes ~200 bytes of kernel memory (VMA overhead)</li>
<li>System limit: typically ~65,000 memory-mapped regions per process</li>
<li>To avoid frequent cache evictions, one can also increase the block size to reduce the total number of blocks</li>
</ul>

<h2 id="contributing">Contributing</h2>

<p>Contributions welcome! Please submit a Pull Request.</p>

<h2 id="license">License</h2>

<p>Apache License 2.0 - see LICENSE file for details.</p>
</div>

                        <input id="mod-tensorblob-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-tensorblob-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="sd">.. include:: ../../README.md</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">._blob</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorBlob</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a><span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;0.1.3&quot;</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>    <span class="s2">&quot;TensorBlob&quot;</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="TensorBlob">
                            <input id="TensorBlob-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TensorBlob</span><wbr>(<span class="base">configmixin._core.ConfigMixin</span>):

                <label class="view-source-button" for="TensorBlob-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob-38"><a href="#TensorBlob-38"><span class="linenos"> 38</span></a><span class="k">class</span><span class="w"> </span><span class="nc">TensorBlob</span><span class="p">(</span><span class="n">ConfigMixin</span><span class="p">):</span>
</span><span id="TensorBlob-39"><a href="#TensorBlob-39"><span class="linenos"> 39</span></a>    <span class="n">_m_rd</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TensorBlob-40"><a href="#TensorBlob-40"><span class="linenos"> 40</span></a>    <span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TensorBlob-41"><a href="#TensorBlob-41"><span class="linenos"> 41</span></a>    <span class="n">_m_ap</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TensorBlob-42"><a href="#TensorBlob-42"><span class="linenos"> 42</span></a>
</span><span id="TensorBlob-43"><a href="#TensorBlob-43"><span class="linenos"> 43</span></a>    <span class="n">status_name</span> <span class="o">=</span> <span class="s2">&quot;.stat&quot;</span>
</span><span id="TensorBlob-44"><a href="#TensorBlob-44"><span class="linenos"> 44</span></a>    <span class="n">config_name</span> <span class="o">=</span> <span class="s2">&quot;.conf&quot;</span>
</span><span id="TensorBlob-45"><a href="#TensorBlob-45"><span class="linenos"> 45</span></a>    <span class="n">ignore_for_config</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;filename&quot;</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="s2">&quot;max_cached_blocks&quot;</span><span class="p">]</span>
</span><span id="TensorBlob-46"><a href="#TensorBlob-46"><span class="linenos"> 46</span></a>
</span><span id="TensorBlob-47"><a href="#TensorBlob-47"><span class="linenos"> 47</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob-48"><a href="#TensorBlob-48"><span class="linenos"> 48</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">open</span><span class="p">(</span>
</span><span id="TensorBlob-49"><a href="#TensorBlob-49"><span class="linenos"> 49</span></a>        <span class="bp">cls</span><span class="p">,</span>
</span><span id="TensorBlob-50"><a href="#TensorBlob-50"><span class="linenos"> 50</span></a>        <span class="n">filename</span><span class="p">,</span>
</span><span id="TensorBlob-51"><a href="#TensorBlob-51"><span class="linenos"> 51</span></a>        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
</span><span id="TensorBlob-52"><a href="#TensorBlob-52"><span class="linenos"> 52</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="TensorBlob-53"><a href="#TensorBlob-53"><span class="linenos"> 53</span></a>        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob-54"><a href="#TensorBlob-54"><span class="linenos"> 54</span></a>        <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob-55"><a href="#TensorBlob-55"><span class="linenos"> 55</span></a>        <span class="n">block_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span>
</span><span id="TensorBlob-56"><a href="#TensorBlob-56"><span class="linenos"> 56</span></a>        <span class="n">max_cached_blocks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob-57"><a href="#TensorBlob-57"><span class="linenos"> 57</span></a>    <span class="p">):</span>
</span><span id="TensorBlob-58"><a href="#TensorBlob-58"><span class="linenos"> 58</span></a><span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Open a TensorBlob with file-like interface for tensor storage.</span>
</span><span id="TensorBlob-59"><a href="#TensorBlob-59"><span class="linenos"> 59</span></a>
</span><span id="TensorBlob-60"><a href="#TensorBlob-60"><span class="linenos"> 60</span></a><span class="sd">        TensorBlob provides persistent, memory-mapped storage for large collections</span>
</span><span id="TensorBlob-61"><a href="#TensorBlob-61"><span class="linenos"> 61</span></a><span class="sd">        of same-shaped tensors. It uses a block-based architecture where tensors are</span>
</span><span id="TensorBlob-62"><a href="#TensorBlob-62"><span class="linenos"> 62</span></a><span class="sd">        organized into fixed-size blocks for efficient I/O and memory management.</span>
</span><span id="TensorBlob-63"><a href="#TensorBlob-63"><span class="linenos"> 63</span></a>
</span><span id="TensorBlob-64"><a href="#TensorBlob-64"><span class="linenos"> 64</span></a><span class="sd">        The blob is stored as a directory containing:</span>
</span><span id="TensorBlob-65"><a href="#TensorBlob-65"><span class="linenos"> 65</span></a><span class="sd">        - ``.conf``: Configuration file (dtype, shape, block_size)</span>
</span><span id="TensorBlob-66"><a href="#TensorBlob-66"><span class="linenos"> 66</span></a><span class="sd">        - ``.stat``: State file (length, block list)</span>
</span><span id="TensorBlob-67"><a href="#TensorBlob-67"><span class="linenos"> 67</span></a><span class="sd">        - Block files: UUID-named memory-mapped tensor files</span>
</span><span id="TensorBlob-68"><a href="#TensorBlob-68"><span class="linenos"> 68</span></a>
</span><span id="TensorBlob-69"><a href="#TensorBlob-69"><span class="linenos"> 69</span></a><span class="sd">        Parameters</span>
</span><span id="TensorBlob-70"><a href="#TensorBlob-70"><span class="linenos"> 70</span></a><span class="sd">        ----------</span>
</span><span id="TensorBlob-71"><a href="#TensorBlob-71"><span class="linenos"> 71</span></a><span class="sd">        filename : str or Path</span>
</span><span id="TensorBlob-72"><a href="#TensorBlob-72"><span class="linenos"> 72</span></a><span class="sd">            Directory path for blob storage. Supports tilde expansion (~) and</span>
</span><span id="TensorBlob-73"><a href="#TensorBlob-73"><span class="linenos"> 73</span></a><span class="sd">            relative paths.</span>
</span><span id="TensorBlob-74"><a href="#TensorBlob-74"><span class="linenos"> 74</span></a><span class="sd">        mode : str, default=&quot;r&quot;</span>
</span><span id="TensorBlob-75"><a href="#TensorBlob-75"><span class="linenos"> 75</span></a><span class="sd">            File access mode (&#39;r&#39;, &#39;w&#39;, &#39;a&#39;, &#39;r+&#39;, &#39;w+&#39;, &#39;a+&#39;). See below for details.</span>
</span><span id="TensorBlob-76"><a href="#TensorBlob-76"><span class="linenos"> 76</span></a><span class="sd">        dtype : str or torch.dtype, optional</span>
</span><span id="TensorBlob-77"><a href="#TensorBlob-77"><span class="linenos"> 77</span></a><span class="sd">            Data type for tensors. Required for new blobs (modes &#39;w&#39;, &#39;w+&#39;).</span>
</span><span id="TensorBlob-78"><a href="#TensorBlob-78"><span class="linenos"> 78</span></a><span class="sd">        shape : tuple of int or int, optional</span>
</span><span id="TensorBlob-79"><a href="#TensorBlob-79"><span class="linenos"> 79</span></a><span class="sd">            Shape of individual tensors. Required for new blobs (modes &#39;w&#39;, &#39;w+&#39;).</span>
</span><span id="TensorBlob-80"><a href="#TensorBlob-80"><span class="linenos"> 80</span></a><span class="sd">        block_size : int, default=8192</span>
</span><span id="TensorBlob-81"><a href="#TensorBlob-81"><span class="linenos"> 81</span></a><span class="sd">            Number of tensors per memory-mapped block file.</span>
</span><span id="TensorBlob-82"><a href="#TensorBlob-82"><span class="linenos"> 82</span></a><span class="sd">        max_cached_blocks : int, optional</span>
</span><span id="TensorBlob-83"><a href="#TensorBlob-83"><span class="linenos"> 83</span></a><span class="sd">            Maximum number of memory-mapped blocks to keep cached. When exceeded,</span>
</span><span id="TensorBlob-84"><a href="#TensorBlob-84"><span class="linenos"> 84</span></a><span class="sd">            least recently used blocks are unmapped. If None (default), uses 1/16</span>
</span><span id="TensorBlob-85"><a href="#TensorBlob-85"><span class="linenos"> 85</span></a><span class="sd">            of system&#39;s max_map_count limit (typically ~4000). This limits kernel</span>
</span><span id="TensorBlob-86"><a href="#TensorBlob-86"><span class="linenos"> 86</span></a><span class="sd">            VMA overhead for blobs with many blocks.</span>
</span><span id="TensorBlob-87"><a href="#TensorBlob-87"><span class="linenos"> 87</span></a>
</span><span id="TensorBlob-88"><a href="#TensorBlob-88"><span class="linenos"> 88</span></a><span class="sd">        Returns</span>
</span><span id="TensorBlob-89"><a href="#TensorBlob-89"><span class="linenos"> 89</span></a><span class="sd">        -------</span>
</span><span id="TensorBlob-90"><a href="#TensorBlob-90"><span class="linenos"> 90</span></a><span class="sd">        TensorBlob</span>
</span><span id="TensorBlob-91"><a href="#TensorBlob-91"><span class="linenos"> 91</span></a><span class="sd">            Opened blob object. Use with context manager for automatic cleanup.</span>
</span><span id="TensorBlob-92"><a href="#TensorBlob-92"><span class="linenos"> 92</span></a>
</span><span id="TensorBlob-93"><a href="#TensorBlob-93"><span class="linenos"> 93</span></a><span class="sd">        Raises</span>
</span><span id="TensorBlob-94"><a href="#TensorBlob-94"><span class="linenos"> 94</span></a><span class="sd">        ------</span>
</span><span id="TensorBlob-95"><a href="#TensorBlob-95"><span class="linenos"> 95</span></a><span class="sd">        FileNotFoundError</span>
</span><span id="TensorBlob-96"><a href="#TensorBlob-96"><span class="linenos"> 96</span></a><span class="sd">            If mode is &#39;r&#39;, &#39;r+&#39;, &#39;a&#39;, or &#39;a+&#39; and blob doesn&#39;t exist.</span>
</span><span id="TensorBlob-97"><a href="#TensorBlob-97"><span class="linenos"> 97</span></a><span class="sd">        ValueError</span>
</span><span id="TensorBlob-98"><a href="#TensorBlob-98"><span class="linenos"> 98</span></a><span class="sd">            If creating new blob without dtype or shape, or if mode is invalid.</span>
</span><span id="TensorBlob-99"><a href="#TensorBlob-99"><span class="linenos"> 99</span></a><span class="sd">        TypeError</span>
</span><span id="TensorBlob-100"><a href="#TensorBlob-100"><span class="linenos">100</span></a><span class="sd">            If dtype is neither string nor torch.dtype.</span>
</span><span id="TensorBlob-101"><a href="#TensorBlob-101"><span class="linenos">101</span></a>
</span><span id="TensorBlob-102"><a href="#TensorBlob-102"><span class="linenos">102</span></a><span class="sd">        Examples</span>
</span><span id="TensorBlob-103"><a href="#TensorBlob-103"><span class="linenos">103</span></a><span class="sd">        --------</span>
</span><span id="TensorBlob-104"><a href="#TensorBlob-104"><span class="linenos">104</span></a><span class="sd">        Creating a new blob and writing data:</span>
</span><span id="TensorBlob-105"><a href="#TensorBlob-105"><span class="linenos">105</span></a>
</span><span id="TensorBlob-106"><a href="#TensorBlob-106"><span class="linenos">106</span></a><span class="sd">        &gt;&gt;&gt; import torch</span>
</span><span id="TensorBlob-107"><a href="#TensorBlob-107"><span class="linenos">107</span></a><span class="sd">        &gt;&gt;&gt; from tensorblob import TensorBlob</span>
</span><span id="TensorBlob-108"><a href="#TensorBlob-108"><span class="linenos">108</span></a><span class="sd">        &gt;&gt;&gt;</span>
</span><span id="TensorBlob-109"><a href="#TensorBlob-109"><span class="linenos">109</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;w&quot;,</span>
</span><span id="TensorBlob-110"><a href="#TensorBlob-110"><span class="linenos">110</span></a><span class="sd">        ...                       dtype=&quot;float32&quot;, shape=(768,)) as blob:</span>
</span><span id="TensorBlob-111"><a href="#TensorBlob-111"><span class="linenos">111</span></a><span class="sd">        ...     embeddings = torch.randn(1000, 768)</span>
</span><span id="TensorBlob-112"><a href="#TensorBlob-112"><span class="linenos">112</span></a><span class="sd">        ...     blob.write(embeddings)</span>
</span><span id="TensorBlob-113"><a href="#TensorBlob-113"><span class="linenos">113</span></a><span class="sd">        ...     print(f&quot;Wrote {len(blob)} tensors&quot;)</span>
</span><span id="TensorBlob-114"><a href="#TensorBlob-114"><span class="linenos">114</span></a><span class="sd">        Wrote 1000 tensors</span>
</span><span id="TensorBlob-115"><a href="#TensorBlob-115"><span class="linenos">115</span></a>
</span><span id="TensorBlob-116"><a href="#TensorBlob-116"><span class="linenos">116</span></a><span class="sd">        Reading from existing blob:</span>
</span><span id="TensorBlob-117"><a href="#TensorBlob-117"><span class="linenos">117</span></a>
</span><span id="TensorBlob-118"><a href="#TensorBlob-118"><span class="linenos">118</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r&quot;) as blob:</span>
</span><span id="TensorBlob-119"><a href="#TensorBlob-119"><span class="linenos">119</span></a><span class="sd">        ...     all_data = blob.read()</span>
</span><span id="TensorBlob-120"><a href="#TensorBlob-120"><span class="linenos">120</span></a><span class="sd">        ...     print(all_data.shape)</span>
</span><span id="TensorBlob-121"><a href="#TensorBlob-121"><span class="linenos">121</span></a><span class="sd">        torch.Size([1000, 768])</span>
</span><span id="TensorBlob-122"><a href="#TensorBlob-122"><span class="linenos">122</span></a>
</span><span id="TensorBlob-123"><a href="#TensorBlob-123"><span class="linenos">123</span></a><span class="sd">        Appending to existing blob:</span>
</span><span id="TensorBlob-124"><a href="#TensorBlob-124"><span class="linenos">124</span></a>
</span><span id="TensorBlob-125"><a href="#TensorBlob-125"><span class="linenos">125</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;a&quot;) as blob:</span>
</span><span id="TensorBlob-126"><a href="#TensorBlob-126"><span class="linenos">126</span></a><span class="sd">        ...     new_data = torch.randn(100, 768)</span>
</span><span id="TensorBlob-127"><a href="#TensorBlob-127"><span class="linenos">127</span></a><span class="sd">        ...     blob.write(new_data)</span>
</span><span id="TensorBlob-128"><a href="#TensorBlob-128"><span class="linenos">128</span></a><span class="sd">        ...     print(f&quot;Total: {len(blob)}&quot;)</span>
</span><span id="TensorBlob-129"><a href="#TensorBlob-129"><span class="linenos">129</span></a><span class="sd">        Total: 1100</span>
</span><span id="TensorBlob-130"><a href="#TensorBlob-130"><span class="linenos">130</span></a>
</span><span id="TensorBlob-131"><a href="#TensorBlob-131"><span class="linenos">131</span></a><span class="sd">        Read and update with r+ mode:</span>
</span><span id="TensorBlob-132"><a href="#TensorBlob-132"><span class="linenos">132</span></a>
</span><span id="TensorBlob-133"><a href="#TensorBlob-133"><span class="linenos">133</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r+&quot;) as blob:</span>
</span><span id="TensorBlob-134"><a href="#TensorBlob-134"><span class="linenos">134</span></a><span class="sd">        ...     first_10 = blob.read(size=10)</span>
</span><span id="TensorBlob-135"><a href="#TensorBlob-135"><span class="linenos">135</span></a><span class="sd">        ...     blob.seek(5)</span>
</span><span id="TensorBlob-136"><a href="#TensorBlob-136"><span class="linenos">136</span></a><span class="sd">        ...     blob.write(torch.ones(3, 768))  # Overwrite at position 5</span>
</span><span id="TensorBlob-137"><a href="#TensorBlob-137"><span class="linenos">137</span></a>
</span><span id="TensorBlob-138"><a href="#TensorBlob-138"><span class="linenos">138</span></a><span class="sd">        Custom block size for large tensors:</span>
</span><span id="TensorBlob-139"><a href="#TensorBlob-139"><span class="linenos">139</span></a>
</span><span id="TensorBlob-140"><a href="#TensorBlob-140"><span class="linenos">140</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/images&quot;, &quot;w&quot;,</span>
</span><span id="TensorBlob-141"><a href="#TensorBlob-141"><span class="linenos">141</span></a><span class="sd">        ...                       dtype=torch.float32,</span>
</span><span id="TensorBlob-142"><a href="#TensorBlob-142"><span class="linenos">142</span></a><span class="sd">        ...                       shape=(3, 1024, 1024),</span>
</span><span id="TensorBlob-143"><a href="#TensorBlob-143"><span class="linenos">143</span></a><span class="sd">        ...                       block_size=256) as blob:</span>
</span><span id="TensorBlob-144"><a href="#TensorBlob-144"><span class="linenos">144</span></a><span class="sd">        ...     images = torch.randn(1000, 3, 1024, 1024)</span>
</span><span id="TensorBlob-145"><a href="#TensorBlob-145"><span class="linenos">145</span></a><span class="sd">        ...     blob.write(images)</span>
</span><span id="TensorBlob-146"><a href="#TensorBlob-146"><span class="linenos">146</span></a>
</span><span id="TensorBlob-147"><a href="#TensorBlob-147"><span class="linenos">147</span></a><span class="sd">        Custom cache size for large-scale random access:</span>
</span><span id="TensorBlob-148"><a href="#TensorBlob-148"><span class="linenos">148</span></a>
</span><span id="TensorBlob-149"><a href="#TensorBlob-149"><span class="linenos">149</span></a><span class="sd">        &gt;&gt;&gt; # Increase cache for better random access performance</span>
</span><span id="TensorBlob-150"><a href="#TensorBlob-150"><span class="linenos">150</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r&quot;,</span>
</span><span id="TensorBlob-151"><a href="#TensorBlob-151"><span class="linenos">151</span></a><span class="sd">        ...                       max_cached_blocks=10000) as blob:</span>
</span><span id="TensorBlob-152"><a href="#TensorBlob-152"><span class="linenos">152</span></a><span class="sd">        ...     for idx in random_indices:</span>
</span><span id="TensorBlob-153"><a href="#TensorBlob-153"><span class="linenos">153</span></a><span class="sd">        ...         embedding = blob[idx]  # Frequently accessed blocks stay cached</span>
</span><span id="TensorBlob-154"><a href="#TensorBlob-154"><span class="linenos">154</span></a>
</span><span id="TensorBlob-155"><a href="#TensorBlob-155"><span class="linenos">155</span></a><span class="sd">        &gt;&gt;&gt; # Decrease cache for memory-constrained environments</span>
</span><span id="TensorBlob-156"><a href="#TensorBlob-156"><span class="linenos">156</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/features&quot;, &quot;r&quot;,</span>
</span><span id="TensorBlob-157"><a href="#TensorBlob-157"><span class="linenos">157</span></a><span class="sd">        ...                       max_cached_blocks=100) as blob:</span>
</span><span id="TensorBlob-158"><a href="#TensorBlob-158"><span class="linenos">158</span></a><span class="sd">        ...     for feature in blob:  # Sequential access works fine</span>
</span><span id="TensorBlob-159"><a href="#TensorBlob-159"><span class="linenos">159</span></a><span class="sd">        ...         process(feature)</span>
</span><span id="TensorBlob-160"><a href="#TensorBlob-160"><span class="linenos">160</span></a>
</span><span id="TensorBlob-161"><a href="#TensorBlob-161"><span class="linenos">161</span></a><span class="sd">        File Access Modes</span>
</span><span id="TensorBlob-162"><a href="#TensorBlob-162"><span class="linenos">162</span></a><span class="sd">        -----------------</span>
</span><span id="TensorBlob-163"><a href="#TensorBlob-163"><span class="linenos">163</span></a><span class="sd">        Similar to Python&#39;s built-in open(), supports the following modes:</span>
</span><span id="TensorBlob-164"><a href="#TensorBlob-164"><span class="linenos">164</span></a>
</span><span id="TensorBlob-165"><a href="#TensorBlob-165"><span class="linenos">165</span></a><span class="sd">        Basic modes:</span>
</span><span id="TensorBlob-166"><a href="#TensorBlob-166"><span class="linenos">166</span></a><span class="sd">        - &#39;r&#39;  : Read-only. Blob must exist. Position starts at beginning.</span>
</span><span id="TensorBlob-167"><a href="#TensorBlob-167"><span class="linenos">167</span></a><span class="sd">        - &#39;w&#39;  : Write-only. Creates new or truncates existing. Position at start. **If the blob already exists,</span>
</span><span id="TensorBlob-168"><a href="#TensorBlob-168"><span class="linenos">168</span></a><span class="sd">                   truncation will ignore any other parameters supplied and rely on existing configuration.**</span>
</span><span id="TensorBlob-169"><a href="#TensorBlob-169"><span class="linenos">169</span></a><span class="sd">        - &#39;a&#39;  : Append-only. Blob must exist. Position starts at end.</span>
</span><span id="TensorBlob-170"><a href="#TensorBlob-170"><span class="linenos">170</span></a><span class="sd">                All writes go to end regardless of seek position.</span>
</span><span id="TensorBlob-171"><a href="#TensorBlob-171"><span class="linenos">171</span></a>
</span><span id="TensorBlob-172"><a href="#TensorBlob-172"><span class="linenos">172</span></a><span class="sd">        Update modes (with &#39;+&#39;):</span>
</span><span id="TensorBlob-173"><a href="#TensorBlob-173"><span class="linenos">173</span></a><span class="sd">        - &#39;r+&#39; : Read and write. Blob must exist. Position at start.</span>
</span><span id="TensorBlob-174"><a href="#TensorBlob-174"><span class="linenos">174</span></a><span class="sd">                   Can overwrite existing data or extend at end.</span>
</span><span id="TensorBlob-175"><a href="#TensorBlob-175"><span class="linenos">175</span></a><span class="sd">        - &#39;w+&#39; : Read and write. Creates new or truncates existing. Position at start.</span>
</span><span id="TensorBlob-176"><a href="#TensorBlob-176"><span class="linenos">176</span></a><span class="sd">        - &#39;a+&#39; : Read and append. Blob must exist. Position at end.</span>
</span><span id="TensorBlob-177"><a href="#TensorBlob-177"><span class="linenos">177</span></a><span class="sd">                   Reads allowed anywhere, writes always append to end.</span>
</span><span id="TensorBlob-178"><a href="#TensorBlob-178"><span class="linenos">178</span></a>
</span><span id="TensorBlob-179"><a href="#TensorBlob-179"><span class="linenos">179</span></a><span class="sd">        Data Type and Shape</span>
</span><span id="TensorBlob-180"><a href="#TensorBlob-180"><span class="linenos">180</span></a><span class="sd">        -------------------</span>
</span><span id="TensorBlob-181"><a href="#TensorBlob-181"><span class="linenos">181</span></a><span class="sd">        All tensors in a blob must have the same dtype and shape. These are</span>
</span><span id="TensorBlob-182"><a href="#TensorBlob-182"><span class="linenos">182</span></a><span class="sd">        specified when creating a new blob (modes &#39;w&#39;, &#39;w+&#39;) and stored in</span>
</span><span id="TensorBlob-183"><a href="#TensorBlob-183"><span class="linenos">183</span></a><span class="sd">        the configuration file. When opening existing blobs, dtype and shape</span>
</span><span id="TensorBlob-184"><a href="#TensorBlob-184"><span class="linenos">184</span></a><span class="sd">        are loaded automatically.</span>
</span><span id="TensorBlob-185"><a href="#TensorBlob-185"><span class="linenos">185</span></a>
</span><span id="TensorBlob-186"><a href="#TensorBlob-186"><span class="linenos">186</span></a><span class="sd">        Supported dtypes: &quot;float32&quot;, &quot;float64&quot;, &quot;int32&quot;, &quot;int64&quot;, &quot;bool&quot;, etc.</span>
</span><span id="TensorBlob-187"><a href="#TensorBlob-187"><span class="linenos">187</span></a><span class="sd">        Can also use torch.dtype objects like torch.float32.</span>
</span><span id="TensorBlob-188"><a href="#TensorBlob-188"><span class="linenos">188</span></a>
</span><span id="TensorBlob-189"><a href="#TensorBlob-189"><span class="linenos">189</span></a><span class="sd">        Shape can be:</span>
</span><span id="TensorBlob-190"><a href="#TensorBlob-190"><span class="linenos">190</span></a><span class="sd">        - Single integer: shape=10 creates 1D tensors of shape (10,)</span>
</span><span id="TensorBlob-191"><a href="#TensorBlob-191"><span class="linenos">191</span></a><span class="sd">        - Tuple: shape=(3, 224, 224) creates 3D tensors</span>
</span><span id="TensorBlob-192"><a href="#TensorBlob-192"><span class="linenos">192</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TensorBlob-193"><a href="#TensorBlob-193"><span class="linenos">193</span></a>        <span class="n">modes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob-194"><a href="#TensorBlob-194"><span class="linenos">194</span></a>        <span class="k">if</span> <span class="n">modes</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="s2">&quot;raw+&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">modes</span><span class="p">):</span>
</span><span id="TensorBlob-195"><a href="#TensorBlob-195"><span class="linenos">195</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid mode: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob-196"><a href="#TensorBlob-196"><span class="linenos">196</span></a>        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span> <span class="ow">in</span> <span class="s2">&quot;raw&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">mode</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="TensorBlob-197"><a href="#TensorBlob-197"><span class="linenos">197</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob-198"><a href="#TensorBlob-198"><span class="linenos">198</span></a>                <span class="s2">&quot;Must have exactly one of read/write/append mode and at most one plus: </span><span class="si">%s</span><span class="s2">&quot;</span>
</span><span id="TensorBlob-199"><a href="#TensorBlob-199"><span class="linenos">199</span></a>                <span class="o">%</span> <span class="n">mode</span>
</span><span id="TensorBlob-200"><a href="#TensorBlob-200"><span class="linenos">200</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-201"><a href="#TensorBlob-201"><span class="linenos">201</span></a>
</span><span id="TensorBlob-202"><a href="#TensorBlob-202"><span class="linenos">202</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
</span><span id="TensorBlob-203"><a href="#TensorBlob-203"><span class="linenos">203</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TensorBlob-204"><a href="#TensorBlob-204"><span class="linenos">204</span></a>            <span class="k">if</span> <span class="s2">&quot;r&quot;</span> <span class="ow">in</span> <span class="n">modes</span> <span class="ow">or</span> <span class="s2">&quot;a&quot;</span> <span class="ow">in</span> <span class="n">modes</span><span class="p">:</span>
</span><span id="TensorBlob-205"><a href="#TensorBlob-205"><span class="linenos">205</span></a>                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;Blob not found: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
</span><span id="TensorBlob-206"><a href="#TensorBlob-206"><span class="linenos">206</span></a>            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-207"><a href="#TensorBlob-207"><span class="linenos">207</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob-208"><a href="#TensorBlob-208"><span class="linenos">208</span></a>                    <span class="s2">&quot;Arguments ``dtype`` and ``shape`` are required for new blob; got: </span><span class="si">%r</span><span class="s2"> and </span><span class="si">%r</span><span class="s2">&quot;</span>
</span><span id="TensorBlob-209"><a href="#TensorBlob-209"><span class="linenos">209</span></a>                    <span class="o">%</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob-210"><a href="#TensorBlob-210"><span class="linenos">210</span></a>                <span class="p">)</span>
</span><span id="TensorBlob-211"><a href="#TensorBlob-211"><span class="linenos">211</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
</span><span id="TensorBlob-212"><a href="#TensorBlob-212"><span class="linenos">212</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
</span><span id="TensorBlob-213"><a href="#TensorBlob-213"><span class="linenos">213</span></a>            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="TensorBlob-214"><a href="#TensorBlob-214"><span class="linenos">214</span></a>                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="TensorBlob-215"><a href="#TensorBlob-215"><span class="linenos">215</span></a>                    <span class="s2">&quot;dtype must be str or torch.dtype, got </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="TensorBlob-216"><a href="#TensorBlob-216"><span class="linenos">216</span></a>                <span class="p">)</span>
</span><span id="TensorBlob-217"><a href="#TensorBlob-217"><span class="linenos">217</span></a>            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob-218"><a href="#TensorBlob-218"><span class="linenos">218</span></a>            <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
</span><span id="TensorBlob-219"><a href="#TensorBlob-219"><span class="linenos">219</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">max_cached_blocks</span>
</span><span id="TensorBlob-220"><a href="#TensorBlob-220"><span class="linenos">220</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-221"><a href="#TensorBlob-221"><span class="linenos">221</span></a>
</span><span id="TensorBlob-222"><a href="#TensorBlob-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>
</span><span id="TensorBlob-223"><a href="#TensorBlob-223"><span class="linenos">223</span></a>            <span class="n">save_directory</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
</span><span id="TensorBlob-224"><a href="#TensorBlob-224"><span class="linenos">224</span></a>            <span class="n">runtime_kwargs</span><span class="o">=</span><span class="p">{</span>
</span><span id="TensorBlob-225"><a href="#TensorBlob-225"><span class="linenos">225</span></a>                <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="n">mode</span><span class="p">,</span>
</span><span id="TensorBlob-226"><a href="#TensorBlob-226"><span class="linenos">226</span></a>                <span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span>
</span><span id="TensorBlob-227"><a href="#TensorBlob-227"><span class="linenos">227</span></a>                <span class="s2">&quot;max_cached_blocks&quot;</span><span class="p">:</span> <span class="n">max_cached_blocks</span><span class="p">,</span>
</span><span id="TensorBlob-228"><a href="#TensorBlob-228"><span class="linenos">228</span></a>            <span class="p">},</span>
</span><span id="TensorBlob-229"><a href="#TensorBlob-229"><span class="linenos">229</span></a>        <span class="p">)</span>
</span><span id="TensorBlob-230"><a href="#TensorBlob-230"><span class="linenos">230</span></a>
</span><span id="TensorBlob-231"><a href="#TensorBlob-231"><span class="linenos">231</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob-232"><a href="#TensorBlob-232"><span class="linenos">232</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">unlink</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
</span><span id="TensorBlob-233"><a href="#TensorBlob-233"><span class="linenos">233</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
</span><span id="TensorBlob-234"><a href="#TensorBlob-234"><span class="linenos">234</span></a>        <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TensorBlob-235"><a href="#TensorBlob-235"><span class="linenos">235</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="TensorBlob-236"><a href="#TensorBlob-236"><span class="linenos">236</span></a>                <span class="k">with</span> <span class="bp">cls</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">_</span><span class="p">:</span>
</span><span id="TensorBlob-237"><a href="#TensorBlob-237"><span class="linenos">237</span></a>                    <span class="k">pass</span>
</span><span id="TensorBlob-238"><a href="#TensorBlob-238"><span class="linenos">238</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">filename</span> <span class="o">/</span> <span class="bp">cls</span><span class="o">.</span><span class="n">config_name</span><span class="p">)</span>
</span><span id="TensorBlob-239"><a href="#TensorBlob-239"><span class="linenos">239</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">filename</span> <span class="o">/</span> <span class="bp">cls</span><span class="o">.</span><span class="n">status_name</span><span class="p">)</span>
</span><span id="TensorBlob-240"><a href="#TensorBlob-240"><span class="linenos">240</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">rmdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span>
</span><span id="TensorBlob-241"><a href="#TensorBlob-241"><span class="linenos">241</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
</span><span id="TensorBlob-242"><a href="#TensorBlob-242"><span class="linenos">242</span></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Failed to unlink blob at </span><span class="si">%r</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">exc</span><span class="p">))</span>
</span><span id="TensorBlob-243"><a href="#TensorBlob-243"><span class="linenos">243</span></a>                <span class="k">return</span> <span class="kc">False</span>
</span><span id="TensorBlob-244"><a href="#TensorBlob-244"><span class="linenos">244</span></a>        <span class="k">return</span> <span class="kc">True</span>
</span><span id="TensorBlob-245"><a href="#TensorBlob-245"><span class="linenos">245</span></a>
</span><span id="TensorBlob-246"><a href="#TensorBlob-246"><span class="linenos">246</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob-247"><a href="#TensorBlob-247"><span class="linenos">247</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">apply_param_hooks</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
</span><span id="TensorBlob-248"><a href="#TensorBlob-248"><span class="linenos">248</span></a>        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">])</span>
</span><span id="TensorBlob-249"><a href="#TensorBlob-249"><span class="linenos">249</span></a>        <span class="k">return</span> <span class="n">d</span>
</span><span id="TensorBlob-250"><a href="#TensorBlob-250"><span class="linenos">250</span></a>
</span><span id="TensorBlob-251"><a href="#TensorBlob-251"><span class="linenos">251</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob-252"><a href="#TensorBlob-252"><span class="linenos">252</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_getsyscachesize</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-253"><a href="#TensorBlob-253"><span class="linenos">253</span></a>        <span class="c1"># Get default cache size for memory-mapped blocks. Returns 1/16 of system&#39;s</span>
</span><span id="TensorBlob-254"><a href="#TensorBlob-254"><span class="linenos">254</span></a>        <span class="c1"># max_map_count to be conservative, typically ~4000, leaving room for other</span>
</span><span id="TensorBlob-255"><a href="#TensorBlob-255"><span class="linenos">255</span></a>        <span class="c1"># VMAs in the process.</span>
</span><span id="TensorBlob-256"><a href="#TensorBlob-256"><span class="linenos">256</span></a>        <span class="n">maxsize</span> <span class="o">=</span> <span class="mi">65536</span>
</span><span id="TensorBlob-257"><a href="#TensorBlob-257"><span class="linenos">257</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TensorBlob-258"><a href="#TensorBlob-258"><span class="linenos">258</span></a>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;/proc/sys/vm/max_map_count&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="TensorBlob-259"><a href="#TensorBlob-259"><span class="linenos">259</span></a>                <span class="n">maxsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
</span><span id="TensorBlob-260"><a href="#TensorBlob-260"><span class="linenos">260</span></a>        <span class="k">except</span> <span class="p">(</span><span class="ne">FileNotFoundError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">,</span> <span class="ne">PermissionError</span><span class="p">):</span>
</span><span id="TensorBlob-261"><a href="#TensorBlob-261"><span class="linenos">261</span></a>            <span class="k">pass</span>
</span><span id="TensorBlob-262"><a href="#TensorBlob-262"><span class="linenos">262</span></a>        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">maxsize</span> <span class="o">//</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
</span><span id="TensorBlob-263"><a href="#TensorBlob-263"><span class="linenos">263</span></a>
</span><span id="TensorBlob-264"><a href="#TensorBlob-264"><span class="linenos">264</span></a>    <span class="nd">@register_to_config</span>
</span><span id="TensorBlob-265"><a href="#TensorBlob-265"><span class="linenos">265</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TensorBlob-266"><a href="#TensorBlob-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="TensorBlob-267"><a href="#TensorBlob-267"><span class="linenos">267</span></a>        <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob-268"><a href="#TensorBlob-268"><span class="linenos">268</span></a>        <span class="n">dtype</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob-269"><a href="#TensorBlob-269"><span class="linenos">269</span></a>        <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="TensorBlob-270"><a href="#TensorBlob-270"><span class="linenos">270</span></a>        <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="TensorBlob-271"><a href="#TensorBlob-271"><span class="linenos">271</span></a>        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob-272"><a href="#TensorBlob-272"><span class="linenos">272</span></a>        <span class="n">max_cached_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob-273"><a href="#TensorBlob-273"><span class="linenos">273</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-274"><a href="#TensorBlob-274"><span class="linenos">274</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
</span><span id="TensorBlob-275"><a href="#TensorBlob-275"><span class="linenos">275</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
</span><span id="TensorBlob-276"><a href="#TensorBlob-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="TensorBlob-277"><a href="#TensorBlob-277"><span class="linenos">277</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
</span><span id="TensorBlob-278"><a href="#TensorBlob-278"><span class="linenos">278</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
</span><span id="TensorBlob-279"><a href="#TensorBlob-279"><span class="linenos">279</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_cached_blocks</span> <span class="o">=</span> <span class="n">max_cached_blocks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getsyscachesize</span><span class="p">()</span>
</span><span id="TensorBlob-280"><a href="#TensorBlob-280"><span class="linenos">280</span></a>
</span><span id="TensorBlob-281"><a href="#TensorBlob-281"><span class="linenos">281</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="TensorBlob-282"><a href="#TensorBlob-282"><span class="linenos">282</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TensorBlob-283"><a href="#TensorBlob-283"><span class="linenos">283</span></a>
</span><span id="TensorBlob-284"><a href="#TensorBlob-284"><span class="linenos">284</span></a>        <span class="k">if</span> <span class="s2">&quot;+&quot;</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
</span><span id="TensorBlob-285"><a href="#TensorBlob-285"><span class="linenos">285</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_m_rd</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-286"><a href="#TensorBlob-286"><span class="linenos">286</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-287"><a href="#TensorBlob-287"><span class="linenos">287</span></a>        <span class="k">match</span> <span class="n">mode</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
</span><span id="TensorBlob-288"><a href="#TensorBlob-288"><span class="linenos">288</span></a>            <span class="k">case</span> <span class="s2">&quot;r&quot;</span><span class="p">:</span>
</span><span id="TensorBlob-289"><a href="#TensorBlob-289"><span class="linenos">289</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_rd</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-290"><a href="#TensorBlob-290"><span class="linenos">290</span></a>            <span class="k">case</span> <span class="s2">&quot;w&quot;</span><span class="p">:</span>
</span><span id="TensorBlob-291"><a href="#TensorBlob-291"><span class="linenos">291</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-292"><a href="#TensorBlob-292"><span class="linenos">292</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_trunc</span><span class="p">()</span>
</span><span id="TensorBlob-293"><a href="#TensorBlob-293"><span class="linenos">293</span></a>            <span class="k">case</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span>
</span><span id="TensorBlob-294"><a href="#TensorBlob-294"><span class="linenos">294</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-295"><a href="#TensorBlob-295"><span class="linenos">295</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_ap</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-296"><a href="#TensorBlob-296"><span class="linenos">296</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>
</span><span id="TensorBlob-297"><a href="#TensorBlob-297"><span class="linenos">297</span></a>
</span><span id="TensorBlob-298"><a href="#TensorBlob-298"><span class="linenos">298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loadstatus</span><span class="p">()</span>
</span><span id="TensorBlob-299"><a href="#TensorBlob-299"><span class="linenos">299</span></a>
</span><span id="TensorBlob-300"><a href="#TensorBlob-300"><span class="linenos">300</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob-301"><a href="#TensorBlob-301"><span class="linenos">301</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">configpath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="TensorBlob-302"><a href="#TensorBlob-302"><span class="linenos">302</span></a>        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config_name</span><span class="p">)</span>
</span><span id="TensorBlob-303"><a href="#TensorBlob-303"><span class="linenos">303</span></a>
</span><span id="TensorBlob-304"><a href="#TensorBlob-304"><span class="linenos">304</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob-305"><a href="#TensorBlob-305"><span class="linenos">305</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">statuspath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="TensorBlob-306"><a href="#TensorBlob-306"><span class="linenos">306</span></a>        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_name</span><span class="p">)</span>
</span><span id="TensorBlob-307"><a href="#TensorBlob-307"><span class="linenos">307</span></a>
</span><span id="TensorBlob-308"><a href="#TensorBlob-308"><span class="linenos">308</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob-309"><a href="#TensorBlob-309"><span class="linenos">309</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">closed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="TensorBlob-310"><a href="#TensorBlob-310"><span class="linenos">310</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span>
</span><span id="TensorBlob-311"><a href="#TensorBlob-311"><span class="linenos">311</span></a>
</span><span id="TensorBlob-312"><a href="#TensorBlob-312"><span class="linenos">312</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorBlob</span><span class="p">:</span>
</span><span id="TensorBlob-313"><a href="#TensorBlob-313"><span class="linenos">313</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="TensorBlob-314"><a href="#TensorBlob-314"><span class="linenos">314</span></a>
</span><span id="TensorBlob-315"><a href="#TensorBlob-315"><span class="linenos">315</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-316"><a href="#TensorBlob-316"><span class="linenos">316</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="TensorBlob-317"><a href="#TensorBlob-317"><span class="linenos">317</span></a>
</span><span id="TensorBlob-318"><a href="#TensorBlob-318"><span class="linenos">318</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-319"><a href="#TensorBlob-319"><span class="linenos">319</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span>
</span><span id="TensorBlob-320"><a href="#TensorBlob-320"><span class="linenos">320</span></a>
</span><span id="TensorBlob-321"><a href="#TensorBlob-321"><span class="linenos">321</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">slice</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="TensorBlob-322"><a href="#TensorBlob-322"><span class="linenos">322</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">)):</span>
</span><span id="TensorBlob-323"><a href="#TensorBlob-323"><span class="linenos">323</span></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Index must be int or slice, got </span><span class="si">%r</span><span class="s2">!&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="TensorBlob-324"><a href="#TensorBlob-324"><span class="linenos">324</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="TensorBlob-325"><a href="#TensorBlob-325"><span class="linenos">325</span></a>            <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="ow">or</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="TensorBlob-326"><a href="#TensorBlob-326"><span class="linenos">326</span></a>                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
</span><span id="TensorBlob-327"><a href="#TensorBlob-327"><span class="linenos">327</span></a>                    <span class="s2">&quot;Index out of bounds: </span><span class="si">%r</span><span class="s2"> (length: </span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob-328"><a href="#TensorBlob-328"><span class="linenos">328</span></a>                <span class="p">)</span>
</span><span id="TensorBlob-329"><a href="#TensorBlob-329"><span class="linenos">329</span></a>            <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob-330"><a href="#TensorBlob-330"><span class="linenos">330</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getblock</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="n">o</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="TensorBlob-331"><a href="#TensorBlob-331"><span class="linenos">331</span></a>
</span><span id="TensorBlob-332"><a href="#TensorBlob-332"><span class="linenos">332</span></a>        <span class="c1"># Although the current implementation may not be efficient, it is very easy to</span>
</span><span id="TensorBlob-333"><a href="#TensorBlob-333"><span class="linenos">333</span></a>        <span class="c1"># understand and debug. More efficient implementation requires much more complex</span>
</span><span id="TensorBlob-334"><a href="#TensorBlob-334"><span class="linenos">334</span></a>        <span class="c1"># edge case handling and is error prone. Also, I think the primary cost here is</span>
</span><span id="TensorBlob-335"><a href="#TensorBlob-335"><span class="linenos">335</span></a>        <span class="c1"># still the I/O operations, not the Python code.</span>
</span><span id="TensorBlob-336"><a href="#TensorBlob-336"><span class="linenos">336</span></a>        <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="TensorBlob-337"><a href="#TensorBlob-337"><span class="linenos">337</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_getblock</span><span class="p">(</span><span class="n">bd</span><span class="p">)[[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">_is</span><span class="p">]]</span>
</span><span id="TensorBlob-338"><a href="#TensorBlob-338"><span class="linenos">338</span></a>            <span class="k">for</span> <span class="n">bd</span><span class="p">,</span> <span class="n">_is</span> <span class="ow">in</span> <span class="n">groupby</span><span class="p">(</span>
</span><span id="TensorBlob-339"><a href="#TensorBlob-339"><span class="linenos">339</span></a>                <span class="nb">range</span><span class="p">(</span><span class="o">*</span><span class="n">idx</span><span class="o">.</span><span class="n">indices</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob-340"><a href="#TensorBlob-340"><span class="linenos">340</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-341"><a href="#TensorBlob-341"><span class="linenos">341</span></a>        <span class="p">]</span>
</span><span id="TensorBlob-342"><a href="#TensorBlob-342"><span class="linenos">342</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
</span><span id="TensorBlob-343"><a href="#TensorBlob-343"><span class="linenos">343</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</span><span id="TensorBlob-344"><a href="#TensorBlob-344"><span class="linenos">344</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="TensorBlob-345"><a href="#TensorBlob-345"><span class="linenos">345</span></a>
</span><span id="TensorBlob-346"><a href="#TensorBlob-346"><span class="linenos">346</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="TensorBlob-347"><a href="#TensorBlob-347"><span class="linenos">347</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
</span><span id="TensorBlob-348"><a href="#TensorBlob-348"><span class="linenos">348</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="TensorBlob-349"><a href="#TensorBlob-349"><span class="linenos">349</span></a>            <span class="k">yield</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="TensorBlob-350"><a href="#TensorBlob-350"><span class="linenos">350</span></a>
</span><span id="TensorBlob-351"><a href="#TensorBlob-351"><span class="linenos">351</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_trunc</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-352"><a href="#TensorBlob-352"><span class="linenos">352</span></a>        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
</span><span id="TensorBlob-353"><a href="#TensorBlob-353"><span class="linenos">353</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="TensorBlob-354"><a href="#TensorBlob-354"><span class="linenos">354</span></a>                <span class="n">st</span> <span class="o">=</span> <span class="n">TensorBlobStatus</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span><span id="TensorBlob-355"><a href="#TensorBlob-355"><span class="linenos">355</span></a>            <span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
</span><span id="TensorBlob-356"><a href="#TensorBlob-356"><span class="linenos">356</span></a>                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
</span><span id="TensorBlob-357"><a href="#TensorBlob-357"><span class="linenos">357</span></a>                    <span class="s2">&quot;Status file missing for blob at </span><span class="si">%r</span><span class="s2">; file corrupted!&quot;</span>
</span><span id="TensorBlob-358"><a href="#TensorBlob-358"><span class="linenos">358</span></a>                    <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span>
</span><span id="TensorBlob-359"><a href="#TensorBlob-359"><span class="linenos">359</span></a>                <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">exc</span>
</span><span id="TensorBlob-360"><a href="#TensorBlob-360"><span class="linenos">360</span></a>            <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">st</span><span class="o">.</span><span class="n">bds</span><span class="p">:</span>
</span><span id="TensorBlob-361"><a href="#TensorBlob-361"><span class="linenos">361</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
</span><span id="TensorBlob-362"><a href="#TensorBlob-362"><span class="linenos">362</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">save_config</span><span class="p">(</span><span class="n">save_directory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TensorBlob-363"><a href="#TensorBlob-363"><span class="linenos">363</span></a>        <span class="n">TensorBlobStatus</span><span class="p">()</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span><span id="TensorBlob-364"><a href="#TensorBlob-364"><span class="linenos">364</span></a>
</span><span id="TensorBlob-365"><a href="#TensorBlob-365"><span class="linenos">365</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_create</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-366"><a href="#TensorBlob-366"><span class="linenos">366</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
</span><span id="TensorBlob-367"><a href="#TensorBlob-367"><span class="linenos">367</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">save_config</span><span class="p">(</span><span class="n">save_directory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">)</span>
</span><span id="TensorBlob-368"><a href="#TensorBlob-368"><span class="linenos">368</span></a>            <span class="n">TensorBlobStatus</span><span class="p">()</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span><span id="TensorBlob-369"><a href="#TensorBlob-369"><span class="linenos">369</span></a>
</span><span id="TensorBlob-370"><a href="#TensorBlob-370"><span class="linenos">370</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_getblock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bd</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MemoryMappedTensor</span><span class="p">:</span>
</span><span id="TensorBlob-371"><a href="#TensorBlob-371"><span class="linenos">371</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">:</span>
</span><span id="TensorBlob-372"><a href="#TensorBlob-372"><span class="linenos">372</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_addblock</span><span class="p">()</span>
</span><span id="TensorBlob-373"><a href="#TensorBlob-373"><span class="linenos">373</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bd</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="TensorBlob-374"><a href="#TensorBlob-374"><span class="linenos">374</span></a>            <span class="n">bd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[</span><span class="n">bd</span><span class="p">]</span>
</span><span id="TensorBlob-375"><a href="#TensorBlob-375"><span class="linenos">375</span></a>        <span class="k">if</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">:</span>
</span><span id="TensorBlob-376"><a href="#TensorBlob-376"><span class="linenos">376</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">bd</span><span class="p">]</span>
</span><span id="TensorBlob-377"><a href="#TensorBlob-377"><span class="linenos">377</span></a>
</span><span id="TensorBlob-378"><a href="#TensorBlob-378"><span class="linenos">378</span></a>        <span class="c1"># If cache no hit, a block is lazy-loaded into the cache. We need to</span>
</span><span id="TensorBlob-379"><a href="#TensorBlob-379"><span class="linenos">379</span></a>        <span class="c1"># avoid the __getitem__ call during return here to not increase the</span>
</span><span id="TensorBlob-380"><a href="#TensorBlob-380"><span class="linenos">380</span></a>        <span class="c1"># cache hit count a second time.</span>
</span><span id="TensorBlob-381"><a href="#TensorBlob-381"><span class="linenos">381</span></a>        <span class="n">block</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">bd</span><span class="p">]</span> <span class="o">=</span> <span class="n">MemoryMappedTensor</span><span class="o">.</span><span class="n">from_filename</span><span class="p">(</span>
</span><span id="TensorBlob-382"><a href="#TensorBlob-382"><span class="linenos">382</span></a>            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">bd</span><span class="p">),</span>
</span><span id="TensorBlob-383"><a href="#TensorBlob-383"><span class="linenos">383</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
</span><span id="TensorBlob-384"><a href="#TensorBlob-384"><span class="linenos">384</span></a>            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
</span><span id="TensorBlob-385"><a href="#TensorBlob-385"><span class="linenos">385</span></a>        <span class="p">)</span>
</span><span id="TensorBlob-386"><a href="#TensorBlob-386"><span class="linenos">386</span></a>        <span class="k">return</span> <span class="n">block</span>
</span><span id="TensorBlob-387"><a href="#TensorBlob-387"><span class="linenos">387</span></a>
</span><span id="TensorBlob-388"><a href="#TensorBlob-388"><span class="linenos">388</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_isfull</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="TensorBlob-389"><a href="#TensorBlob-389"><span class="linenos">389</span></a>        <span class="k">return</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob-390"><a href="#TensorBlob-390"><span class="linenos">390</span></a>
</span><span id="TensorBlob-391"><a href="#TensorBlob-391"><span class="linenos">391</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_addblock</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MemoryMappedTensor</span><span class="p">:</span>
</span><span id="TensorBlob-392"><a href="#TensorBlob-392"><span class="linenos">392</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_isfull</span><span class="p">():</span>
</span><span id="TensorBlob-393"><a href="#TensorBlob-393"><span class="linenos">393</span></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="TensorBlob-394"><a href="#TensorBlob-394"><span class="linenos">394</span></a>                <span class="s2">&quot;Attempt to create a new block when working block &quot;</span>
</span><span id="TensorBlob-395"><a href="#TensorBlob-395"><span class="linenos">395</span></a>                <span class="s2">&quot;is not full: length &lt;</span><span class="si">%d</span><span class="s2">&gt; &lt; capacity &lt;</span><span class="si">%d</span><span class="s2">&gt;.&quot;</span>
</span><span id="TensorBlob-396"><a href="#TensorBlob-396"><span class="linenos">396</span></a>                <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob-397"><a href="#TensorBlob-397"><span class="linenos">397</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-398"><a href="#TensorBlob-398"><span class="linenos">398</span></a>        <span class="n">name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
</span><span id="TensorBlob-399"><a href="#TensorBlob-399"><span class="linenos">399</span></a>        <span class="n">mmap</span> <span class="o">=</span> <span class="n">MemoryMappedTensor</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
</span><span id="TensorBlob-400"><a href="#TensorBlob-400"><span class="linenos">400</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span>
</span><span id="TensorBlob-401"><a href="#TensorBlob-401"><span class="linenos">401</span></a>            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
</span><span id="TensorBlob-402"><a href="#TensorBlob-402"><span class="linenos">402</span></a>            <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
</span><span id="TensorBlob-403"><a href="#TensorBlob-403"><span class="linenos">403</span></a>            <span class="n">filename</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">name</span><span class="p">),</span>
</span><span id="TensorBlob-404"><a href="#TensorBlob-404"><span class="linenos">404</span></a>        <span class="p">)</span>
</span><span id="TensorBlob-405"><a href="#TensorBlob-405"><span class="linenos">405</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</span><span id="TensorBlob-406"><a href="#TensorBlob-406"><span class="linenos">406</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">mmap</span>
</span><span id="TensorBlob-407"><a href="#TensorBlob-407"><span class="linenos">407</span></a>        <span class="k">return</span> <span class="n">mmap</span>
</span><span id="TensorBlob-408"><a href="#TensorBlob-408"><span class="linenos">408</span></a>
</span><span id="TensorBlob-409"><a href="#TensorBlob-409"><span class="linenos">409</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_loadstatus</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-410"><a href="#TensorBlob-410"><span class="linenos">410</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TensorBlob-411"><a href="#TensorBlob-411"><span class="linenos">411</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span> <span class="o">=</span> <span class="n">TensorBlobStatus</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span><span id="TensorBlob-412"><a href="#TensorBlob-412"><span class="linenos">412</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span> <span class="o">=</span> <span class="n">LRUCache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_cached_blocks</span><span class="p">)</span>
</span><span id="TensorBlob-413"><a href="#TensorBlob-413"><span class="linenos">413</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_ap</span><span class="p">:</span>
</span><span id="TensorBlob-414"><a href="#TensorBlob-414"><span class="linenos">414</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span><span id="TensorBlob-415"><a href="#TensorBlob-415"><span class="linenos">415</span></a>        <span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
</span><span id="TensorBlob-416"><a href="#TensorBlob-416"><span class="linenos">416</span></a>            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
</span><span id="TensorBlob-417"><a href="#TensorBlob-417"><span class="linenos">417</span></a>                <span class="s2">&quot;status file missing for blob at </span><span class="si">%r</span><span class="s2">; file corrupted!&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span>
</span><span id="TensorBlob-418"><a href="#TensorBlob-418"><span class="linenos">418</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">exc</span>
</span><span id="TensorBlob-419"><a href="#TensorBlob-419"><span class="linenos">419</span></a>
</span><span id="TensorBlob-420"><a href="#TensorBlob-420"><span class="linenos">420</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_checkclosed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-421"><a href="#TensorBlob-421"><span class="linenos">421</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
</span><span id="TensorBlob-422"><a href="#TensorBlob-422"><span class="linenos">422</span></a>            <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s2">&quot;I/O operation on closed blob.&quot;</span><span class="p">)</span>
</span><span id="TensorBlob-423"><a href="#TensorBlob-423"><span class="linenos">423</span></a>
</span><span id="TensorBlob-424"><a href="#TensorBlob-424"><span class="linenos">424</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_checkwritable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-425"><a href="#TensorBlob-425"><span class="linenos">425</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span><span class="p">:</span>
</span><span id="TensorBlob-426"><a href="#TensorBlob-426"><span class="linenos">426</span></a>            <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s2">&quot;Blob is not open for writing (mode=&#39;</span><span class="si">%s</span><span class="s2">&#39;)&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob-427"><a href="#TensorBlob-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob-428"><a href="#TensorBlob-428"><span class="linenos">428</span></a>
</span><span id="TensorBlob-429"><a href="#TensorBlob-429"><span class="linenos">429</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_checkreadable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-430"><a href="#TensorBlob-430"><span class="linenos">430</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_rd</span><span class="p">:</span>
</span><span id="TensorBlob-431"><a href="#TensorBlob-431"><span class="linenos">431</span></a>            <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s2">&quot;Blob is not open for reading (mode=&#39;</span><span class="si">%s</span><span class="s2">&#39;)&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob-432"><a href="#TensorBlob-432"><span class="linenos">432</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob-433"><a href="#TensorBlob-433"><span class="linenos">433</span></a>
</span><span id="TensorBlob-434"><a href="#TensorBlob-434"><span class="linenos">434</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">tell</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-435"><a href="#TensorBlob-435"><span class="linenos">435</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob-436"><a href="#TensorBlob-436"><span class="linenos">436</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span>
</span><span id="TensorBlob-437"><a href="#TensorBlob-437"><span class="linenos">437</span></a>
</span><span id="TensorBlob-438"><a href="#TensorBlob-438"><span class="linenos">438</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">seek</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">whence</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_SET</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-439"><a href="#TensorBlob-439"><span class="linenos">439</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob-440"><a href="#TensorBlob-440"><span class="linenos">440</span></a>        <span class="k">match</span> <span class="n">whence</span><span class="p">:</span>
</span><span id="TensorBlob-441"><a href="#TensorBlob-441"><span class="linenos">441</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_SET</span><span class="p">:</span>
</span><span id="TensorBlob-442"><a href="#TensorBlob-442"><span class="linenos">442</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="n">pos</span>
</span><span id="TensorBlob-443"><a href="#TensorBlob-443"><span class="linenos">443</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_CUR</span><span class="p">:</span>
</span><span id="TensorBlob-444"><a href="#TensorBlob-444"><span class="linenos">444</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+</span> <span class="n">pos</span>
</span><span id="TensorBlob-445"><a href="#TensorBlob-445"><span class="linenos">445</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">:</span>
</span><span id="TensorBlob-446"><a href="#TensorBlob-446"><span class="linenos">446</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="n">pos</span>
</span><span id="TensorBlob-447"><a href="#TensorBlob-447"><span class="linenos">447</span></a>            <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="TensorBlob-448"><a href="#TensorBlob-448"><span class="linenos">448</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid whence: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">whence</span><span class="p">)</span>
</span><span id="TensorBlob-449"><a href="#TensorBlob-449"><span class="linenos">449</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">_pos</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="TensorBlob-450"><a href="#TensorBlob-450"><span class="linenos">450</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span><span id="TensorBlob-451"><a href="#TensorBlob-451"><span class="linenos">451</span></a>
</span><span id="TensorBlob-452"><a href="#TensorBlob-452"><span class="linenos">452</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-453"><a href="#TensorBlob-453"><span class="linenos">453</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span><span class="p">:</span>
</span><span id="TensorBlob-454"><a href="#TensorBlob-454"><span class="linenos">454</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span><span id="TensorBlob-455"><a href="#TensorBlob-455"><span class="linenos">455</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob-456"><a href="#TensorBlob-456"><span class="linenos">456</span></a>
</span><span id="TensorBlob-457"><a href="#TensorBlob-457"><span class="linenos">457</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-458"><a href="#TensorBlob-458"><span class="linenos">458</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob-459"><a href="#TensorBlob-459"><span class="linenos">459</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span><span id="TensorBlob-460"><a href="#TensorBlob-460"><span class="linenos">460</span></a>
</span><span id="TensorBlob-461"><a href="#TensorBlob-461"><span class="linenos">461</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="TensorBlob-462"><a href="#TensorBlob-462"><span class="linenos">462</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkreadable</span><span class="p">()</span>
</span><span id="TensorBlob-463"><a href="#TensorBlob-463"><span class="linenos">463</span></a>        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+</span> <span class="p">(</span><span class="n">size</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob-464"><a href="#TensorBlob-464"><span class="linenos">464</span></a>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="p">:</span> <span class="n">end</span><span class="p">]</span>
</span><span id="TensorBlob-465"><a href="#TensorBlob-465"><span class="linenos">465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
</span><span id="TensorBlob-466"><a href="#TensorBlob-466"><span class="linenos">466</span></a>        <span class="k">return</span> <span class="n">ret</span>
</span><span id="TensorBlob-467"><a href="#TensorBlob-467"><span class="linenos">467</span></a>
</span><span id="TensorBlob-468"><a href="#TensorBlob-468"><span class="linenos">468</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-469"><a href="#TensorBlob-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob-470"><a href="#TensorBlob-470"><span class="linenos">470</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_ap</span><span class="p">:</span>
</span><span id="TensorBlob-471"><a href="#TensorBlob-471"><span class="linenos">471</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob-472"><a href="#TensorBlob-472"><span class="linenos">472</span></a>        <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob-473"><a href="#TensorBlob-473"><span class="linenos">473</span></a>        <span class="n">nt</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="TensorBlob-474"><a href="#TensorBlob-474"><span class="linenos">474</span></a>
</span><span id="TensorBlob-475"><a href="#TensorBlob-475"><span class="linenos">475</span></a>        <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="TensorBlob-476"><a href="#TensorBlob-476"><span class="linenos">476</span></a>        <span class="k">while</span> <span class="n">cnt</span> <span class="o">&lt;</span> <span class="n">nt</span><span class="p">:</span>
</span><span id="TensorBlob-477"><a href="#TensorBlob-477"><span class="linenos">477</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_isfull</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="TensorBlob-478"><a href="#TensorBlob-478"><span class="linenos">478</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_addblock</span><span class="p">()</span>
</span><span id="TensorBlob-479"><a href="#TensorBlob-479"><span class="linenos">479</span></a>            <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob-480"><a href="#TensorBlob-480"><span class="linenos">480</span></a>            <span class="n">incr</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">-</span> <span class="n">o</span><span class="p">,</span> <span class="n">nt</span> <span class="o">-</span> <span class="n">cnt</span><span class="p">)</span>
</span><span id="TensorBlob-481"><a href="#TensorBlob-481"><span class="linenos">481</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_getblock</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="n">o</span> <span class="p">:</span> <span class="n">o</span> <span class="o">+</span> <span class="n">incr</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts</span><span class="p">[</span><span class="n">cnt</span> <span class="p">:</span> <span class="n">cnt</span> <span class="o">+</span> <span class="n">incr</span><span class="p">]</span>
</span><span id="TensorBlob-482"><a href="#TensorBlob-482"><span class="linenos">482</span></a>
</span><span id="TensorBlob-483"><a href="#TensorBlob-483"><span class="linenos">483</span></a>            <span class="c1"># Update status length for new tensors exceeding the original range only, because</span>
</span><span id="TensorBlob-484"><a href="#TensorBlob-484"><span class="linenos">484</span></a>            <span class="c1"># the cursor may not always be the at EOF and the number of tensors written could</span>
</span><span id="TensorBlob-485"><a href="#TensorBlob-485"><span class="linenos">485</span></a>            <span class="c1"># be smaller than change in length</span>
</span><span id="TensorBlob-486"><a href="#TensorBlob-486"><span class="linenos">486</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+=</span> <span class="n">incr</span>
</span><span id="TensorBlob-487"><a href="#TensorBlob-487"><span class="linenos">487</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">+=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob-488"><a href="#TensorBlob-488"><span class="linenos">488</span></a>
</span><span id="TensorBlob-489"><a href="#TensorBlob-489"><span class="linenos">489</span></a>            <span class="n">cnt</span> <span class="o">+=</span> <span class="n">incr</span>
</span><span id="TensorBlob-490"><a href="#TensorBlob-490"><span class="linenos">490</span></a>
</span><span id="TensorBlob-491"><a href="#TensorBlob-491"><span class="linenos">491</span></a>        <span class="k">assert</span> <span class="n">cnt</span> <span class="o">==</span> <span class="n">nt</span><span class="p">,</span> <span class="s2">&quot;Write incomplete: wrote </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> tensors!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cnt</span><span class="p">,</span> <span class="n">nt</span><span class="p">)</span>
</span><span id="TensorBlob-492"><a href="#TensorBlob-492"><span class="linenos">492</span></a>        <span class="k">return</span> <span class="n">cnt</span>
</span><span id="TensorBlob-493"><a href="#TensorBlob-493"><span class="linenos">493</span></a>
</span><span id="TensorBlob-494"><a href="#TensorBlob-494"><span class="linenos">494</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">truncate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob-495"><a href="#TensorBlob-495"><span class="linenos">495</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob-496"><a href="#TensorBlob-496"><span class="linenos">496</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">pos</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">())</span>
</span><span id="TensorBlob-497"><a href="#TensorBlob-497"><span class="linenos">497</span></a>        <span class="n">brk</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob-498"><a href="#TensorBlob-498"><span class="linenos">498</span></a>        <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[</span><span class="n">brk</span><span class="p">:]:</span>
</span><span id="TensorBlob-499"><a href="#TensorBlob-499"><span class="linenos">499</span></a>            <span class="k">if</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">:</span>
</span><span id="TensorBlob-500"><a href="#TensorBlob-500"><span class="linenos">500</span></a>                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">bd</span><span class="p">]</span>
</span><span id="TensorBlob-501"><a href="#TensorBlob-501"><span class="linenos">501</span></a>            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
</span><span id="TensorBlob-502"><a href="#TensorBlob-502"><span class="linenos">502</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[:</span><span class="n">brk</span><span class="p">]</span>
</span><span id="TensorBlob-503"><a href="#TensorBlob-503"><span class="linenos">503</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span><span id="TensorBlob-504"><a href="#TensorBlob-504"><span class="linenos">504</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span><span id="TensorBlob-505"><a href="#TensorBlob-505"><span class="linenos">505</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span><span id="TensorBlob-506"><a href="#TensorBlob-506"><span class="linenos">506</span></a>
</span><span id="TensorBlob-507"><a href="#TensorBlob-507"><span class="linenos">507</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">extend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">TensorBlob</span><span class="p">,</span> <span class="n">maintain_order</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob-508"><a href="#TensorBlob-508"><span class="linenos">508</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="TensorBlob-509"><a href="#TensorBlob-509"><span class="linenos">509</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Blob data types and shapes must match to extend blobs!&quot;</span><span class="p">)</span>
</span><span id="TensorBlob-510"><a href="#TensorBlob-510"><span class="linenos">510</span></a>
</span><span id="TensorBlob-511"><a href="#TensorBlob-511"><span class="linenos">511</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob-512"><a href="#TensorBlob-512"><span class="linenos">512</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob-513"><a href="#TensorBlob-513"><span class="linenos">513</span></a>
</span><span id="TensorBlob-514"><a href="#TensorBlob-514"><span class="linenos">514</span></a>        <span class="c1"># TODO: Honestly this is a bit inefficient but I think this is rarely used.</span>
</span><span id="TensorBlob-515"><a href="#TensorBlob-515"><span class="linenos">515</span></a>        <span class="k">if</span> <span class="n">maintain_order</span><span class="p">:</span>
</span><span id="TensorBlob-516"><a href="#TensorBlob-516"><span class="linenos">516</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)):</span>
</span><span id="TensorBlob-517"><a href="#TensorBlob-517"><span class="linenos">517</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">other</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="TensorBlob-518"><a href="#TensorBlob-518"><span class="linenos">518</span></a>            <span class="k">return</span>
</span><span id="TensorBlob-519"><a href="#TensorBlob-519"><span class="linenos">519</span></a>
</span><span id="TensorBlob-520"><a href="#TensorBlob-520"><span class="linenos">520</span></a>        <span class="c1"># If order is not important, we can simply copy over the complete blocks from</span>
</span><span id="TensorBlob-521"><a href="#TensorBlob-521"><span class="linenos">521</span></a>        <span class="c1"># the other blob and merge incomplete blocks.</span>
</span><span id="TensorBlob-522"><a href="#TensorBlob-522"><span class="linenos">522</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span><span class="p">:</span>
</span><span id="TensorBlob-523"><a href="#TensorBlob-523"><span class="linenos">523</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob-524"><a href="#TensorBlob-524"><span class="linenos">524</span></a>                <span class="s2">&quot;Block sizes must match to extend blobs in non-order-preserving mode!&quot;</span>
</span><span id="TensorBlob-525"><a href="#TensorBlob-525"><span class="linenos">525</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-526"><a href="#TensorBlob-526"><span class="linenos">526</span></a>
</span><span id="TensorBlob-527"><a href="#TensorBlob-527"><span class="linenos">527</span></a>        <span class="n">comb</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="TensorBlob-528"><a href="#TensorBlob-528"><span class="linenos">528</span></a>        <span class="n">sbrk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob-529"><a href="#TensorBlob-529"><span class="linenos">529</span></a>        <span class="k">if</span> <span class="n">sbrk</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="TensorBlob-530"><a href="#TensorBlob-530"><span class="linenos">530</span></a>            <span class="n">comb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">sbrk</span><span class="p">:])</span>
</span><span id="TensorBlob-531"><a href="#TensorBlob-531"><span class="linenos">531</span></a>        <span class="n">obrk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="o">//</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob-532"><a href="#TensorBlob-532"><span class="linenos">532</span></a>        <span class="k">if</span> <span class="n">obrk</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">):</span>
</span><span id="TensorBlob-533"><a href="#TensorBlob-533"><span class="linenos">533</span></a>            <span class="n">comb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">other</span><span class="p">[</span><span class="n">obrk</span><span class="p">:])</span>
</span><span id="TensorBlob-534"><a href="#TensorBlob-534"><span class="linenos">534</span></a>
</span><span id="TensorBlob-535"><a href="#TensorBlob-535"><span class="linenos">535</span></a>        <span class="c1"># TODO: We are directly accessing internal data structures of the other blob here.</span>
</span><span id="TensorBlob-536"><a href="#TensorBlob-536"><span class="linenos">536</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">sbrk</span><span class="p">)</span>
</span><span id="TensorBlob-537"><a href="#TensorBlob-537"><span class="linenos">537</span></a>        <span class="k">for</span> <span class="n">obd</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="o">//</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span><span class="p">]:</span>
</span><span id="TensorBlob-538"><a href="#TensorBlob-538"><span class="linenos">538</span></a>            <span class="n">sbd</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
</span><span id="TensorBlob-539"><a href="#TensorBlob-539"><span class="linenos">539</span></a>            <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span>
</span><span id="TensorBlob-540"><a href="#TensorBlob-540"><span class="linenos">540</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">obd</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">sbd</span><span class="p">)</span>
</span><span id="TensorBlob-541"><a href="#TensorBlob-541"><span class="linenos">541</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-542"><a href="#TensorBlob-542"><span class="linenos">542</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sbd</span><span class="p">)</span>
</span><span id="TensorBlob-543"><a href="#TensorBlob-543"><span class="linenos">543</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob-544"><a href="#TensorBlob-544"><span class="linenos">544</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">sbd</span><span class="p">]</span> <span class="o">=</span> <span class="n">MemoryMappedTensor</span><span class="o">.</span><span class="n">from_filename</span><span class="p">(</span>
</span><span id="TensorBlob-545"><a href="#TensorBlob-545"><span class="linenos">545</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">sbd</span><span class="p">),</span>
</span><span id="TensorBlob-546"><a href="#TensorBlob-546"><span class="linenos">546</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
</span><span id="TensorBlob-547"><a href="#TensorBlob-547"><span class="linenos">547</span></a>                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
</span><span id="TensorBlob-548"><a href="#TensorBlob-548"><span class="linenos">548</span></a>            <span class="p">)</span>
</span><span id="TensorBlob-549"><a href="#TensorBlob-549"><span class="linenos">549</span></a>
</span><span id="TensorBlob-550"><a href="#TensorBlob-550"><span class="linenos">550</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob-551"><a href="#TensorBlob-551"><span class="linenos">551</span></a>        <span class="k">if</span> <span class="n">comb</span><span class="p">:</span>
</span><span id="TensorBlob-552"><a href="#TensorBlob-552"><span class="linenos">552</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">comb</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="TensorBlob-553"><a href="#TensorBlob-553"><span class="linenos">553</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Mixin class for automated configuration registration and IO.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>config_name</strong> (str, default=None):
Class attribute that specifies the filename under which the config should be stored when calling
<code><a href="#TensorBlob.save_config">save_config</a></code>. Should be overridden by the subclass.</li>
<li><strong>ignore_for_config</strong> (list[str], default=[]):
Class attribute that specifies a list of attributes that should not be saved in the config. Should
be overridden by the subclass.</li>
</ul>

<h6 id="examples">Examples</h6>

<p>In this example, we have a model with 3 arguments:</p>

<ul>
<li><code>hidden_size</code>: The hidden size of the model.</li>
<li><code>_num_layers</code>: The number of layers in the model.</li>
<li><code>dropout</code>: The dropout rate of the model.</li>
</ul>

<p>Among the three arguments, the number of layers is implicitly ignored by the decorator because of the leading
underscore; the <code>dropout</code> argument is explicitly based on the specification in <code><a href="#TensorBlob.ignore_for_config">ignore_for_config</a></code> class
variable. The <code>hidden_size</code> argument is registered to the config.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">MyModel</span><span class="p">(</span><span class="n">ConfigMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">config_name</span> <span class="o">=</span> <span class="s2">&quot;my_model_config.json&quot;</span>
<span class="gp">... </span>    <span class="n">ignore_for_config</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="nd">@register_to_config</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span> <span class="n">_num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">_num_layers</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>  <span class="c1"># This will be ignored because of the specification in `ignore_for_config`</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">_num_layers</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">config</span>
<span class="go">mappingproxy({&#39;__notes__&#39;: {&#39;class_name&#39;: &#39;MyModel&#39;, &#39;using_default_values&#39;: [], &#39;args&#39;: (), &#39;kwargs&#39;: {}}, &#39;hidden_size&#39;: 1024})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">num_layers</span>
<span class="go">20</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">dropout</span>
<span class="go">0.2</span>
</code></pre>
</div>
</div>


                            <div id="TensorBlob.__init__" class="classattr">
                                        <input id="TensorBlob.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-register_to_config">@register_to_config</div>

        <span class="name">TensorBlob</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">filename</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">dtype</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>,</span><span class="param">	<span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">mode</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">max_cached_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="TensorBlob.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.__init__-264"><a href="#TensorBlob.__init__-264"><span class="linenos">264</span></a>    <span class="nd">@register_to_config</span>
</span><span id="TensorBlob.__init__-265"><a href="#TensorBlob.__init__-265"><span class="linenos">265</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TensorBlob.__init__-266"><a href="#TensorBlob.__init__-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-267"><a href="#TensorBlob.__init__-267"><span class="linenos">267</span></a>        <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-268"><a href="#TensorBlob.__init__-268"><span class="linenos">268</span></a>        <span class="n">dtype</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-269"><a href="#TensorBlob.__init__-269"><span class="linenos">269</span></a>        <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
</span><span id="TensorBlob.__init__-270"><a href="#TensorBlob.__init__-270"><span class="linenos">270</span></a>        <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-271"><a href="#TensorBlob.__init__-271"><span class="linenos">271</span></a>        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-272"><a href="#TensorBlob.__init__-272"><span class="linenos">272</span></a>        <span class="n">max_cached_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob.__init__-273"><a href="#TensorBlob.__init__-273"><span class="linenos">273</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob.__init__-274"><a href="#TensorBlob.__init__-274"><span class="linenos">274</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
</span><span id="TensorBlob.__init__-275"><a href="#TensorBlob.__init__-275"><span class="linenos">275</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
</span><span id="TensorBlob.__init__-276"><a href="#TensorBlob.__init__-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="TensorBlob.__init__-277"><a href="#TensorBlob.__init__-277"><span class="linenos">277</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
</span><span id="TensorBlob.__init__-278"><a href="#TensorBlob.__init__-278"><span class="linenos">278</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
</span><span id="TensorBlob.__init__-279"><a href="#TensorBlob.__init__-279"><span class="linenos">279</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_cached_blocks</span> <span class="o">=</span> <span class="n">max_cached_blocks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getsyscachesize</span><span class="p">()</span>
</span><span id="TensorBlob.__init__-280"><a href="#TensorBlob.__init__-280"><span class="linenos">280</span></a>
</span><span id="TensorBlob.__init__-281"><a href="#TensorBlob.__init__-281"><span class="linenos">281</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="TensorBlob.__init__-282"><a href="#TensorBlob.__init__-282"><span class="linenos">282</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="TensorBlob.__init__-283"><a href="#TensorBlob.__init__-283"><span class="linenos">283</span></a>
</span><span id="TensorBlob.__init__-284"><a href="#TensorBlob.__init__-284"><span class="linenos">284</span></a>        <span class="k">if</span> <span class="s2">&quot;+&quot;</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
</span><span id="TensorBlob.__init__-285"><a href="#TensorBlob.__init__-285"><span class="linenos">285</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_m_rd</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-286"><a href="#TensorBlob.__init__-286"><span class="linenos">286</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-287"><a href="#TensorBlob.__init__-287"><span class="linenos">287</span></a>        <span class="k">match</span> <span class="n">mode</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
</span><span id="TensorBlob.__init__-288"><a href="#TensorBlob.__init__-288"><span class="linenos">288</span></a>            <span class="k">case</span> <span class="s2">&quot;r&quot;</span><span class="p">:</span>
</span><span id="TensorBlob.__init__-289"><a href="#TensorBlob.__init__-289"><span class="linenos">289</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_rd</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-290"><a href="#TensorBlob.__init__-290"><span class="linenos">290</span></a>            <span class="k">case</span> <span class="s2">&quot;w&quot;</span><span class="p">:</span>
</span><span id="TensorBlob.__init__-291"><a href="#TensorBlob.__init__-291"><span class="linenos">291</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-292"><a href="#TensorBlob.__init__-292"><span class="linenos">292</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_trunc</span><span class="p">()</span>
</span><span id="TensorBlob.__init__-293"><a href="#TensorBlob.__init__-293"><span class="linenos">293</span></a>            <span class="k">case</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span>
</span><span id="TensorBlob.__init__-294"><a href="#TensorBlob.__init__-294"><span class="linenos">294</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-295"><a href="#TensorBlob.__init__-295"><span class="linenos">295</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_m_ap</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TensorBlob.__init__-296"><a href="#TensorBlob.__init__-296"><span class="linenos">296</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_create</span><span class="p">()</span>
</span><span id="TensorBlob.__init__-297"><a href="#TensorBlob.__init__-297"><span class="linenos">297</span></a>
</span><span id="TensorBlob.__init__-298"><a href="#TensorBlob.__init__-298"><span class="linenos">298</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loadstatus</span><span class="p">()</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.status_name" class="classattr">
                                <div class="attr variable">
            <span class="name">status_name</span>        =
<span class="default_value">&#39;.stat&#39;</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.status_name"></a>
    
    

                            </div>
                            <div id="TensorBlob.config_name" class="classattr">
                                <div class="attr variable">
            <span class="name">config_name</span>        =
<span class="default_value">&#39;.conf&#39;</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.config_name"></a>
    
    

                            </div>
                            <div id="TensorBlob.ignore_for_config" class="classattr">
                                <div class="attr variable">
            <span class="name">ignore_for_config</span>        =
<span class="default_value">[&#39;filename&#39;, &#39;mode&#39;, &#39;max_cached_blocks&#39;]</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.ignore_for_config"></a>
    
    

                            </div>
                            <div id="TensorBlob.open" class="classattr">
                                        <input id="TensorBlob.open-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">open</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">cls</span>,</span><span class="param">	<span class="n">filename</span>,</span><span class="param">	<span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">dtype</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">shape</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">block_size</span><span class="o">=</span><span class="mi">8192</span>,</span><span class="param">	<span class="n">max_cached_blocks</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="TensorBlob.open-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.open"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.open-47"><a href="#TensorBlob.open-47"><span class="linenos"> 47</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob.open-48"><a href="#TensorBlob.open-48"><span class="linenos"> 48</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">open</span><span class="p">(</span>
</span><span id="TensorBlob.open-49"><a href="#TensorBlob.open-49"><span class="linenos"> 49</span></a>        <span class="bp">cls</span><span class="p">,</span>
</span><span id="TensorBlob.open-50"><a href="#TensorBlob.open-50"><span class="linenos"> 50</span></a>        <span class="n">filename</span><span class="p">,</span>
</span><span id="TensorBlob.open-51"><a href="#TensorBlob.open-51"><span class="linenos"> 51</span></a>        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
</span><span id="TensorBlob.open-52"><a href="#TensorBlob.open-52"><span class="linenos"> 52</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="TensorBlob.open-53"><a href="#TensorBlob.open-53"><span class="linenos"> 53</span></a>        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob.open-54"><a href="#TensorBlob.open-54"><span class="linenos"> 54</span></a>        <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob.open-55"><a href="#TensorBlob.open-55"><span class="linenos"> 55</span></a>        <span class="n">block_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span>
</span><span id="TensorBlob.open-56"><a href="#TensorBlob.open-56"><span class="linenos"> 56</span></a>        <span class="n">max_cached_blocks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="TensorBlob.open-57"><a href="#TensorBlob.open-57"><span class="linenos"> 57</span></a>    <span class="p">):</span>
</span><span id="TensorBlob.open-58"><a href="#TensorBlob.open-58"><span class="linenos"> 58</span></a><span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Open a TensorBlob with file-like interface for tensor storage.</span>
</span><span id="TensorBlob.open-59"><a href="#TensorBlob.open-59"><span class="linenos"> 59</span></a>
</span><span id="TensorBlob.open-60"><a href="#TensorBlob.open-60"><span class="linenos"> 60</span></a><span class="sd">        TensorBlob provides persistent, memory-mapped storage for large collections</span>
</span><span id="TensorBlob.open-61"><a href="#TensorBlob.open-61"><span class="linenos"> 61</span></a><span class="sd">        of same-shaped tensors. It uses a block-based architecture where tensors are</span>
</span><span id="TensorBlob.open-62"><a href="#TensorBlob.open-62"><span class="linenos"> 62</span></a><span class="sd">        organized into fixed-size blocks for efficient I/O and memory management.</span>
</span><span id="TensorBlob.open-63"><a href="#TensorBlob.open-63"><span class="linenos"> 63</span></a>
</span><span id="TensorBlob.open-64"><a href="#TensorBlob.open-64"><span class="linenos"> 64</span></a><span class="sd">        The blob is stored as a directory containing:</span>
</span><span id="TensorBlob.open-65"><a href="#TensorBlob.open-65"><span class="linenos"> 65</span></a><span class="sd">        - ``.conf``: Configuration file (dtype, shape, block_size)</span>
</span><span id="TensorBlob.open-66"><a href="#TensorBlob.open-66"><span class="linenos"> 66</span></a><span class="sd">        - ``.stat``: State file (length, block list)</span>
</span><span id="TensorBlob.open-67"><a href="#TensorBlob.open-67"><span class="linenos"> 67</span></a><span class="sd">        - Block files: UUID-named memory-mapped tensor files</span>
</span><span id="TensorBlob.open-68"><a href="#TensorBlob.open-68"><span class="linenos"> 68</span></a>
</span><span id="TensorBlob.open-69"><a href="#TensorBlob.open-69"><span class="linenos"> 69</span></a><span class="sd">        Parameters</span>
</span><span id="TensorBlob.open-70"><a href="#TensorBlob.open-70"><span class="linenos"> 70</span></a><span class="sd">        ----------</span>
</span><span id="TensorBlob.open-71"><a href="#TensorBlob.open-71"><span class="linenos"> 71</span></a><span class="sd">        filename : str or Path</span>
</span><span id="TensorBlob.open-72"><a href="#TensorBlob.open-72"><span class="linenos"> 72</span></a><span class="sd">            Directory path for blob storage. Supports tilde expansion (~) and</span>
</span><span id="TensorBlob.open-73"><a href="#TensorBlob.open-73"><span class="linenos"> 73</span></a><span class="sd">            relative paths.</span>
</span><span id="TensorBlob.open-74"><a href="#TensorBlob.open-74"><span class="linenos"> 74</span></a><span class="sd">        mode : str, default=&quot;r&quot;</span>
</span><span id="TensorBlob.open-75"><a href="#TensorBlob.open-75"><span class="linenos"> 75</span></a><span class="sd">            File access mode (&#39;r&#39;, &#39;w&#39;, &#39;a&#39;, &#39;r+&#39;, &#39;w+&#39;, &#39;a+&#39;). See below for details.</span>
</span><span id="TensorBlob.open-76"><a href="#TensorBlob.open-76"><span class="linenos"> 76</span></a><span class="sd">        dtype : str or torch.dtype, optional</span>
</span><span id="TensorBlob.open-77"><a href="#TensorBlob.open-77"><span class="linenos"> 77</span></a><span class="sd">            Data type for tensors. Required for new blobs (modes &#39;w&#39;, &#39;w+&#39;).</span>
</span><span id="TensorBlob.open-78"><a href="#TensorBlob.open-78"><span class="linenos"> 78</span></a><span class="sd">        shape : tuple of int or int, optional</span>
</span><span id="TensorBlob.open-79"><a href="#TensorBlob.open-79"><span class="linenos"> 79</span></a><span class="sd">            Shape of individual tensors. Required for new blobs (modes &#39;w&#39;, &#39;w+&#39;).</span>
</span><span id="TensorBlob.open-80"><a href="#TensorBlob.open-80"><span class="linenos"> 80</span></a><span class="sd">        block_size : int, default=8192</span>
</span><span id="TensorBlob.open-81"><a href="#TensorBlob.open-81"><span class="linenos"> 81</span></a><span class="sd">            Number of tensors per memory-mapped block file.</span>
</span><span id="TensorBlob.open-82"><a href="#TensorBlob.open-82"><span class="linenos"> 82</span></a><span class="sd">        max_cached_blocks : int, optional</span>
</span><span id="TensorBlob.open-83"><a href="#TensorBlob.open-83"><span class="linenos"> 83</span></a><span class="sd">            Maximum number of memory-mapped blocks to keep cached. When exceeded,</span>
</span><span id="TensorBlob.open-84"><a href="#TensorBlob.open-84"><span class="linenos"> 84</span></a><span class="sd">            least recently used blocks are unmapped. If None (default), uses 1/16</span>
</span><span id="TensorBlob.open-85"><a href="#TensorBlob.open-85"><span class="linenos"> 85</span></a><span class="sd">            of system&#39;s max_map_count limit (typically ~4000). This limits kernel</span>
</span><span id="TensorBlob.open-86"><a href="#TensorBlob.open-86"><span class="linenos"> 86</span></a><span class="sd">            VMA overhead for blobs with many blocks.</span>
</span><span id="TensorBlob.open-87"><a href="#TensorBlob.open-87"><span class="linenos"> 87</span></a>
</span><span id="TensorBlob.open-88"><a href="#TensorBlob.open-88"><span class="linenos"> 88</span></a><span class="sd">        Returns</span>
</span><span id="TensorBlob.open-89"><a href="#TensorBlob.open-89"><span class="linenos"> 89</span></a><span class="sd">        -------</span>
</span><span id="TensorBlob.open-90"><a href="#TensorBlob.open-90"><span class="linenos"> 90</span></a><span class="sd">        TensorBlob</span>
</span><span id="TensorBlob.open-91"><a href="#TensorBlob.open-91"><span class="linenos"> 91</span></a><span class="sd">            Opened blob object. Use with context manager for automatic cleanup.</span>
</span><span id="TensorBlob.open-92"><a href="#TensorBlob.open-92"><span class="linenos"> 92</span></a>
</span><span id="TensorBlob.open-93"><a href="#TensorBlob.open-93"><span class="linenos"> 93</span></a><span class="sd">        Raises</span>
</span><span id="TensorBlob.open-94"><a href="#TensorBlob.open-94"><span class="linenos"> 94</span></a><span class="sd">        ------</span>
</span><span id="TensorBlob.open-95"><a href="#TensorBlob.open-95"><span class="linenos"> 95</span></a><span class="sd">        FileNotFoundError</span>
</span><span id="TensorBlob.open-96"><a href="#TensorBlob.open-96"><span class="linenos"> 96</span></a><span class="sd">            If mode is &#39;r&#39;, &#39;r+&#39;, &#39;a&#39;, or &#39;a+&#39; and blob doesn&#39;t exist.</span>
</span><span id="TensorBlob.open-97"><a href="#TensorBlob.open-97"><span class="linenos"> 97</span></a><span class="sd">        ValueError</span>
</span><span id="TensorBlob.open-98"><a href="#TensorBlob.open-98"><span class="linenos"> 98</span></a><span class="sd">            If creating new blob without dtype or shape, or if mode is invalid.</span>
</span><span id="TensorBlob.open-99"><a href="#TensorBlob.open-99"><span class="linenos"> 99</span></a><span class="sd">        TypeError</span>
</span><span id="TensorBlob.open-100"><a href="#TensorBlob.open-100"><span class="linenos">100</span></a><span class="sd">            If dtype is neither string nor torch.dtype.</span>
</span><span id="TensorBlob.open-101"><a href="#TensorBlob.open-101"><span class="linenos">101</span></a>
</span><span id="TensorBlob.open-102"><a href="#TensorBlob.open-102"><span class="linenos">102</span></a><span class="sd">        Examples</span>
</span><span id="TensorBlob.open-103"><a href="#TensorBlob.open-103"><span class="linenos">103</span></a><span class="sd">        --------</span>
</span><span id="TensorBlob.open-104"><a href="#TensorBlob.open-104"><span class="linenos">104</span></a><span class="sd">        Creating a new blob and writing data:</span>
</span><span id="TensorBlob.open-105"><a href="#TensorBlob.open-105"><span class="linenos">105</span></a>
</span><span id="TensorBlob.open-106"><a href="#TensorBlob.open-106"><span class="linenos">106</span></a><span class="sd">        &gt;&gt;&gt; import torch</span>
</span><span id="TensorBlob.open-107"><a href="#TensorBlob.open-107"><span class="linenos">107</span></a><span class="sd">        &gt;&gt;&gt; from tensorblob import TensorBlob</span>
</span><span id="TensorBlob.open-108"><a href="#TensorBlob.open-108"><span class="linenos">108</span></a><span class="sd">        &gt;&gt;&gt;</span>
</span><span id="TensorBlob.open-109"><a href="#TensorBlob.open-109"><span class="linenos">109</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;w&quot;,</span>
</span><span id="TensorBlob.open-110"><a href="#TensorBlob.open-110"><span class="linenos">110</span></a><span class="sd">        ...                       dtype=&quot;float32&quot;, shape=(768,)) as blob:</span>
</span><span id="TensorBlob.open-111"><a href="#TensorBlob.open-111"><span class="linenos">111</span></a><span class="sd">        ...     embeddings = torch.randn(1000, 768)</span>
</span><span id="TensorBlob.open-112"><a href="#TensorBlob.open-112"><span class="linenos">112</span></a><span class="sd">        ...     blob.write(embeddings)</span>
</span><span id="TensorBlob.open-113"><a href="#TensorBlob.open-113"><span class="linenos">113</span></a><span class="sd">        ...     print(f&quot;Wrote {len(blob)} tensors&quot;)</span>
</span><span id="TensorBlob.open-114"><a href="#TensorBlob.open-114"><span class="linenos">114</span></a><span class="sd">        Wrote 1000 tensors</span>
</span><span id="TensorBlob.open-115"><a href="#TensorBlob.open-115"><span class="linenos">115</span></a>
</span><span id="TensorBlob.open-116"><a href="#TensorBlob.open-116"><span class="linenos">116</span></a><span class="sd">        Reading from existing blob:</span>
</span><span id="TensorBlob.open-117"><a href="#TensorBlob.open-117"><span class="linenos">117</span></a>
</span><span id="TensorBlob.open-118"><a href="#TensorBlob.open-118"><span class="linenos">118</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r&quot;) as blob:</span>
</span><span id="TensorBlob.open-119"><a href="#TensorBlob.open-119"><span class="linenos">119</span></a><span class="sd">        ...     all_data = blob.read()</span>
</span><span id="TensorBlob.open-120"><a href="#TensorBlob.open-120"><span class="linenos">120</span></a><span class="sd">        ...     print(all_data.shape)</span>
</span><span id="TensorBlob.open-121"><a href="#TensorBlob.open-121"><span class="linenos">121</span></a><span class="sd">        torch.Size([1000, 768])</span>
</span><span id="TensorBlob.open-122"><a href="#TensorBlob.open-122"><span class="linenos">122</span></a>
</span><span id="TensorBlob.open-123"><a href="#TensorBlob.open-123"><span class="linenos">123</span></a><span class="sd">        Appending to existing blob:</span>
</span><span id="TensorBlob.open-124"><a href="#TensorBlob.open-124"><span class="linenos">124</span></a>
</span><span id="TensorBlob.open-125"><a href="#TensorBlob.open-125"><span class="linenos">125</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;a&quot;) as blob:</span>
</span><span id="TensorBlob.open-126"><a href="#TensorBlob.open-126"><span class="linenos">126</span></a><span class="sd">        ...     new_data = torch.randn(100, 768)</span>
</span><span id="TensorBlob.open-127"><a href="#TensorBlob.open-127"><span class="linenos">127</span></a><span class="sd">        ...     blob.write(new_data)</span>
</span><span id="TensorBlob.open-128"><a href="#TensorBlob.open-128"><span class="linenos">128</span></a><span class="sd">        ...     print(f&quot;Total: {len(blob)}&quot;)</span>
</span><span id="TensorBlob.open-129"><a href="#TensorBlob.open-129"><span class="linenos">129</span></a><span class="sd">        Total: 1100</span>
</span><span id="TensorBlob.open-130"><a href="#TensorBlob.open-130"><span class="linenos">130</span></a>
</span><span id="TensorBlob.open-131"><a href="#TensorBlob.open-131"><span class="linenos">131</span></a><span class="sd">        Read and update with r+ mode:</span>
</span><span id="TensorBlob.open-132"><a href="#TensorBlob.open-132"><span class="linenos">132</span></a>
</span><span id="TensorBlob.open-133"><a href="#TensorBlob.open-133"><span class="linenos">133</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r+&quot;) as blob:</span>
</span><span id="TensorBlob.open-134"><a href="#TensorBlob.open-134"><span class="linenos">134</span></a><span class="sd">        ...     first_10 = blob.read(size=10)</span>
</span><span id="TensorBlob.open-135"><a href="#TensorBlob.open-135"><span class="linenos">135</span></a><span class="sd">        ...     blob.seek(5)</span>
</span><span id="TensorBlob.open-136"><a href="#TensorBlob.open-136"><span class="linenos">136</span></a><span class="sd">        ...     blob.write(torch.ones(3, 768))  # Overwrite at position 5</span>
</span><span id="TensorBlob.open-137"><a href="#TensorBlob.open-137"><span class="linenos">137</span></a>
</span><span id="TensorBlob.open-138"><a href="#TensorBlob.open-138"><span class="linenos">138</span></a><span class="sd">        Custom block size for large tensors:</span>
</span><span id="TensorBlob.open-139"><a href="#TensorBlob.open-139"><span class="linenos">139</span></a>
</span><span id="TensorBlob.open-140"><a href="#TensorBlob.open-140"><span class="linenos">140</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/images&quot;, &quot;w&quot;,</span>
</span><span id="TensorBlob.open-141"><a href="#TensorBlob.open-141"><span class="linenos">141</span></a><span class="sd">        ...                       dtype=torch.float32,</span>
</span><span id="TensorBlob.open-142"><a href="#TensorBlob.open-142"><span class="linenos">142</span></a><span class="sd">        ...                       shape=(3, 1024, 1024),</span>
</span><span id="TensorBlob.open-143"><a href="#TensorBlob.open-143"><span class="linenos">143</span></a><span class="sd">        ...                       block_size=256) as blob:</span>
</span><span id="TensorBlob.open-144"><a href="#TensorBlob.open-144"><span class="linenos">144</span></a><span class="sd">        ...     images = torch.randn(1000, 3, 1024, 1024)</span>
</span><span id="TensorBlob.open-145"><a href="#TensorBlob.open-145"><span class="linenos">145</span></a><span class="sd">        ...     blob.write(images)</span>
</span><span id="TensorBlob.open-146"><a href="#TensorBlob.open-146"><span class="linenos">146</span></a>
</span><span id="TensorBlob.open-147"><a href="#TensorBlob.open-147"><span class="linenos">147</span></a><span class="sd">        Custom cache size for large-scale random access:</span>
</span><span id="TensorBlob.open-148"><a href="#TensorBlob.open-148"><span class="linenos">148</span></a>
</span><span id="TensorBlob.open-149"><a href="#TensorBlob.open-149"><span class="linenos">149</span></a><span class="sd">        &gt;&gt;&gt; # Increase cache for better random access performance</span>
</span><span id="TensorBlob.open-150"><a href="#TensorBlob.open-150"><span class="linenos">150</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/embeddings&quot;, &quot;r&quot;,</span>
</span><span id="TensorBlob.open-151"><a href="#TensorBlob.open-151"><span class="linenos">151</span></a><span class="sd">        ...                       max_cached_blocks=10000) as blob:</span>
</span><span id="TensorBlob.open-152"><a href="#TensorBlob.open-152"><span class="linenos">152</span></a><span class="sd">        ...     for idx in random_indices:</span>
</span><span id="TensorBlob.open-153"><a href="#TensorBlob.open-153"><span class="linenos">153</span></a><span class="sd">        ...         embedding = blob[idx]  # Frequently accessed blocks stay cached</span>
</span><span id="TensorBlob.open-154"><a href="#TensorBlob.open-154"><span class="linenos">154</span></a>
</span><span id="TensorBlob.open-155"><a href="#TensorBlob.open-155"><span class="linenos">155</span></a><span class="sd">        &gt;&gt;&gt; # Decrease cache for memory-constrained environments</span>
</span><span id="TensorBlob.open-156"><a href="#TensorBlob.open-156"><span class="linenos">156</span></a><span class="sd">        &gt;&gt;&gt; with TensorBlob.open(&quot;data/features&quot;, &quot;r&quot;,</span>
</span><span id="TensorBlob.open-157"><a href="#TensorBlob.open-157"><span class="linenos">157</span></a><span class="sd">        ...                       max_cached_blocks=100) as blob:</span>
</span><span id="TensorBlob.open-158"><a href="#TensorBlob.open-158"><span class="linenos">158</span></a><span class="sd">        ...     for feature in blob:  # Sequential access works fine</span>
</span><span id="TensorBlob.open-159"><a href="#TensorBlob.open-159"><span class="linenos">159</span></a><span class="sd">        ...         process(feature)</span>
</span><span id="TensorBlob.open-160"><a href="#TensorBlob.open-160"><span class="linenos">160</span></a>
</span><span id="TensorBlob.open-161"><a href="#TensorBlob.open-161"><span class="linenos">161</span></a><span class="sd">        File Access Modes</span>
</span><span id="TensorBlob.open-162"><a href="#TensorBlob.open-162"><span class="linenos">162</span></a><span class="sd">        -----------------</span>
</span><span id="TensorBlob.open-163"><a href="#TensorBlob.open-163"><span class="linenos">163</span></a><span class="sd">        Similar to Python&#39;s built-in open(), supports the following modes:</span>
</span><span id="TensorBlob.open-164"><a href="#TensorBlob.open-164"><span class="linenos">164</span></a>
</span><span id="TensorBlob.open-165"><a href="#TensorBlob.open-165"><span class="linenos">165</span></a><span class="sd">        Basic modes:</span>
</span><span id="TensorBlob.open-166"><a href="#TensorBlob.open-166"><span class="linenos">166</span></a><span class="sd">        - &#39;r&#39;  : Read-only. Blob must exist. Position starts at beginning.</span>
</span><span id="TensorBlob.open-167"><a href="#TensorBlob.open-167"><span class="linenos">167</span></a><span class="sd">        - &#39;w&#39;  : Write-only. Creates new or truncates existing. Position at start. **If the blob already exists,</span>
</span><span id="TensorBlob.open-168"><a href="#TensorBlob.open-168"><span class="linenos">168</span></a><span class="sd">                   truncation will ignore any other parameters supplied and rely on existing configuration.**</span>
</span><span id="TensorBlob.open-169"><a href="#TensorBlob.open-169"><span class="linenos">169</span></a><span class="sd">        - &#39;a&#39;  : Append-only. Blob must exist. Position starts at end.</span>
</span><span id="TensorBlob.open-170"><a href="#TensorBlob.open-170"><span class="linenos">170</span></a><span class="sd">                All writes go to end regardless of seek position.</span>
</span><span id="TensorBlob.open-171"><a href="#TensorBlob.open-171"><span class="linenos">171</span></a>
</span><span id="TensorBlob.open-172"><a href="#TensorBlob.open-172"><span class="linenos">172</span></a><span class="sd">        Update modes (with &#39;+&#39;):</span>
</span><span id="TensorBlob.open-173"><a href="#TensorBlob.open-173"><span class="linenos">173</span></a><span class="sd">        - &#39;r+&#39; : Read and write. Blob must exist. Position at start.</span>
</span><span id="TensorBlob.open-174"><a href="#TensorBlob.open-174"><span class="linenos">174</span></a><span class="sd">                   Can overwrite existing data or extend at end.</span>
</span><span id="TensorBlob.open-175"><a href="#TensorBlob.open-175"><span class="linenos">175</span></a><span class="sd">        - &#39;w+&#39; : Read and write. Creates new or truncates existing. Position at start.</span>
</span><span id="TensorBlob.open-176"><a href="#TensorBlob.open-176"><span class="linenos">176</span></a><span class="sd">        - &#39;a+&#39; : Read and append. Blob must exist. Position at end.</span>
</span><span id="TensorBlob.open-177"><a href="#TensorBlob.open-177"><span class="linenos">177</span></a><span class="sd">                   Reads allowed anywhere, writes always append to end.</span>
</span><span id="TensorBlob.open-178"><a href="#TensorBlob.open-178"><span class="linenos">178</span></a>
</span><span id="TensorBlob.open-179"><a href="#TensorBlob.open-179"><span class="linenos">179</span></a><span class="sd">        Data Type and Shape</span>
</span><span id="TensorBlob.open-180"><a href="#TensorBlob.open-180"><span class="linenos">180</span></a><span class="sd">        -------------------</span>
</span><span id="TensorBlob.open-181"><a href="#TensorBlob.open-181"><span class="linenos">181</span></a><span class="sd">        All tensors in a blob must have the same dtype and shape. These are</span>
</span><span id="TensorBlob.open-182"><a href="#TensorBlob.open-182"><span class="linenos">182</span></a><span class="sd">        specified when creating a new blob (modes &#39;w&#39;, &#39;w+&#39;) and stored in</span>
</span><span id="TensorBlob.open-183"><a href="#TensorBlob.open-183"><span class="linenos">183</span></a><span class="sd">        the configuration file. When opening existing blobs, dtype and shape</span>
</span><span id="TensorBlob.open-184"><a href="#TensorBlob.open-184"><span class="linenos">184</span></a><span class="sd">        are loaded automatically.</span>
</span><span id="TensorBlob.open-185"><a href="#TensorBlob.open-185"><span class="linenos">185</span></a>
</span><span id="TensorBlob.open-186"><a href="#TensorBlob.open-186"><span class="linenos">186</span></a><span class="sd">        Supported dtypes: &quot;float32&quot;, &quot;float64&quot;, &quot;int32&quot;, &quot;int64&quot;, &quot;bool&quot;, etc.</span>
</span><span id="TensorBlob.open-187"><a href="#TensorBlob.open-187"><span class="linenos">187</span></a><span class="sd">        Can also use torch.dtype objects like torch.float32.</span>
</span><span id="TensorBlob.open-188"><a href="#TensorBlob.open-188"><span class="linenos">188</span></a>
</span><span id="TensorBlob.open-189"><a href="#TensorBlob.open-189"><span class="linenos">189</span></a><span class="sd">        Shape can be:</span>
</span><span id="TensorBlob.open-190"><a href="#TensorBlob.open-190"><span class="linenos">190</span></a><span class="sd">        - Single integer: shape=10 creates 1D tensors of shape (10,)</span>
</span><span id="TensorBlob.open-191"><a href="#TensorBlob.open-191"><span class="linenos">191</span></a><span class="sd">        - Tuple: shape=(3, 224, 224) creates 3D tensors</span>
</span><span id="TensorBlob.open-192"><a href="#TensorBlob.open-192"><span class="linenos">192</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TensorBlob.open-193"><a href="#TensorBlob.open-193"><span class="linenos">193</span></a>        <span class="n">modes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob.open-194"><a href="#TensorBlob.open-194"><span class="linenos">194</span></a>        <span class="k">if</span> <span class="n">modes</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="s2">&quot;raw+&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">modes</span><span class="p">):</span>
</span><span id="TensorBlob.open-195"><a href="#TensorBlob.open-195"><span class="linenos">195</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid mode: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span><span class="p">)</span>
</span><span id="TensorBlob.open-196"><a href="#TensorBlob.open-196"><span class="linenos">196</span></a>        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span> <span class="ow">in</span> <span class="s2">&quot;raw&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">mode</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="TensorBlob.open-197"><a href="#TensorBlob.open-197"><span class="linenos">197</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob.open-198"><a href="#TensorBlob.open-198"><span class="linenos">198</span></a>                <span class="s2">&quot;Must have exactly one of read/write/append mode and at most one plus: </span><span class="si">%s</span><span class="s2">&quot;</span>
</span><span id="TensorBlob.open-199"><a href="#TensorBlob.open-199"><span class="linenos">199</span></a>                <span class="o">%</span> <span class="n">mode</span>
</span><span id="TensorBlob.open-200"><a href="#TensorBlob.open-200"><span class="linenos">200</span></a>            <span class="p">)</span>
</span><span id="TensorBlob.open-201"><a href="#TensorBlob.open-201"><span class="linenos">201</span></a>
</span><span id="TensorBlob.open-202"><a href="#TensorBlob.open-202"><span class="linenos">202</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
</span><span id="TensorBlob.open-203"><a href="#TensorBlob.open-203"><span class="linenos">203</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TensorBlob.open-204"><a href="#TensorBlob.open-204"><span class="linenos">204</span></a>            <span class="k">if</span> <span class="s2">&quot;r&quot;</span> <span class="ow">in</span> <span class="n">modes</span> <span class="ow">or</span> <span class="s2">&quot;a&quot;</span> <span class="ow">in</span> <span class="n">modes</span><span class="p">:</span>
</span><span id="TensorBlob.open-205"><a href="#TensorBlob.open-205"><span class="linenos">205</span></a>                <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="s2">&quot;Blob not found: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
</span><span id="TensorBlob.open-206"><a href="#TensorBlob.open-206"><span class="linenos">206</span></a>            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob.open-207"><a href="#TensorBlob.open-207"><span class="linenos">207</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob.open-208"><a href="#TensorBlob.open-208"><span class="linenos">208</span></a>                    <span class="s2">&quot;Arguments ``dtype`` and ``shape`` are required for new blob; got: </span><span class="si">%r</span><span class="s2"> and </span><span class="si">%r</span><span class="s2">&quot;</span>
</span><span id="TensorBlob.open-209"><a href="#TensorBlob.open-209"><span class="linenos">209</span></a>                    <span class="o">%</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob.open-210"><a href="#TensorBlob.open-210"><span class="linenos">210</span></a>                <span class="p">)</span>
</span><span id="TensorBlob.open-211"><a href="#TensorBlob.open-211"><span class="linenos">211</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
</span><span id="TensorBlob.open-212"><a href="#TensorBlob.open-212"><span class="linenos">212</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
</span><span id="TensorBlob.open-213"><a href="#TensorBlob.open-213"><span class="linenos">213</span></a>            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="TensorBlob.open-214"><a href="#TensorBlob.open-214"><span class="linenos">214</span></a>                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="TensorBlob.open-215"><a href="#TensorBlob.open-215"><span class="linenos">215</span></a>                    <span class="s2">&quot;dtype must be str or torch.dtype, got </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="TensorBlob.open-216"><a href="#TensorBlob.open-216"><span class="linenos">216</span></a>                <span class="p">)</span>
</span><span id="TensorBlob.open-217"><a href="#TensorBlob.open-217"><span class="linenos">217</span></a>            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob.open-218"><a href="#TensorBlob.open-218"><span class="linenos">218</span></a>            <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
</span><span id="TensorBlob.open-219"><a href="#TensorBlob.open-219"><span class="linenos">219</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">max_cached_blocks</span>
</span><span id="TensorBlob.open-220"><a href="#TensorBlob.open-220"><span class="linenos">220</span></a>            <span class="p">)</span>
</span><span id="TensorBlob.open-221"><a href="#TensorBlob.open-221"><span class="linenos">221</span></a>
</span><span id="TensorBlob.open-222"><a href="#TensorBlob.open-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>
</span><span id="TensorBlob.open-223"><a href="#TensorBlob.open-223"><span class="linenos">223</span></a>            <span class="n">save_directory</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
</span><span id="TensorBlob.open-224"><a href="#TensorBlob.open-224"><span class="linenos">224</span></a>            <span class="n">runtime_kwargs</span><span class="o">=</span><span class="p">{</span>
</span><span id="TensorBlob.open-225"><a href="#TensorBlob.open-225"><span class="linenos">225</span></a>                <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="n">mode</span><span class="p">,</span>
</span><span id="TensorBlob.open-226"><a href="#TensorBlob.open-226"><span class="linenos">226</span></a>                <span class="s2">&quot;filename&quot;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span>
</span><span id="TensorBlob.open-227"><a href="#TensorBlob.open-227"><span class="linenos">227</span></a>                <span class="s2">&quot;max_cached_blocks&quot;</span><span class="p">:</span> <span class="n">max_cached_blocks</span><span class="p">,</span>
</span><span id="TensorBlob.open-228"><a href="#TensorBlob.open-228"><span class="linenos">228</span></a>            <span class="p">},</span>
</span><span id="TensorBlob.open-229"><a href="#TensorBlob.open-229"><span class="linenos">229</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Open a TensorBlob with file-like interface for tensor storage.</p>

<p>TensorBlob provides persistent, memory-mapped storage for large collections
of same-shaped tensors. It uses a block-based architecture where tensors are
organized into fixed-size blocks for efficient I/O and memory management.</p>

<p>The blob is stored as a directory containing:</p>

<ul>
<li><code>.conf</code>: Configuration file (dtype, shape, block_size)</li>
<li><code>.stat</code>: State file (length, block list)</li>
<li>Block files: UUID-named memory-mapped tensor files</li>
</ul>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>filename</strong> (str or Path):
Directory path for blob storage. Supports tilde expansion (~) and
relative paths.</li>
<li><strong>mode</strong> (str, default="r"):
File access mode ('r', 'w', 'a', 'r+', 'w+', 'a+'). See below for details.</li>
<li><strong>dtype</strong> (str or torch.dtype, optional):
Data type for tensors. Required for new blobs (modes 'w', 'w+').</li>
<li><strong>shape</strong> (tuple of int or int, optional):
Shape of individual tensors. Required for new blobs (modes 'w', 'w+').</li>
<li><strong>block_size</strong> (int, default=8192):
Number of tensors per memory-mapped block file.</li>
<li><strong>max_cached_blocks</strong> (int, optional):
Maximum number of memory-mapped blocks to keep cached. When exceeded,
least recently used blocks are unmapped. If None (default), uses 1/16
of system's max_map_count limit (typically ~4000). This limits kernel
VMA overhead for blobs with many blocks.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>TensorBlob</strong>: Opened blob object. Use with context manager for automatic cleanup.</li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>FileNotFoundError</strong>: If mode is 'r', 'r+', 'a', or 'a+' and blob doesn't exist.</li>
<li><strong>ValueError</strong>: If creating new blob without dtype or shape, or if mode is invalid.</li>
<li><strong>TypeError</strong>: If dtype is neither string nor torch.dtype.</li>
</ul>

<h6 id="examples">Examples</h6>

<p>Creating a new blob and writing data:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorblob</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorBlob</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">768</span><span class="p">,))</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span><span class="si">}</span><span class="s2"> tensors&quot;</span><span class="p">)</span>
<span class="go">Wrote 1000 tensors</span>
</code></pre>
</div>

<p>Reading from existing blob:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">all_data</span> <span class="o">=</span> <span class="n">blob</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">all_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">torch.Size([1000, 768])</span>
</code></pre>
</div>

<p>Appending to existing blob:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">new_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Total: 1100</span>
</code></pre>
</div>

<p>Read and update with r+ mode:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;r+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">first_10</span> <span class="o">=</span> <span class="n">blob</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">blob</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>  <span class="c1"># Overwrite at position 5</span>
</code></pre>
</div>

<p>Custom block size for large tensors:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/images&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
<span class="gp">... </span>                      <span class="n">block_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">blob</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre>
</div>

<p>Custom cache size for large-scale random access:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Increase cache for better random access performance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/embeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">max_cached_blocks</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">random_indices</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">embedding</span> <span class="o">=</span> <span class="n">blob</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Frequently accessed blocks stay cached</span>
</code></pre>
</div>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Decrease cache for memory-constrained environments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#TensorBlob.open">TensorBlob.open</a></span><span class="p">(</span><span class="s2">&quot;data/features&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">max_cached_blocks</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="k">as</span> <span class="n">blob</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">blob</span><span class="p">:</span>  <span class="c1"># Sequential access works fine</span>
<span class="gp">... </span>        <span class="n">process</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
</code></pre>
</div>

<h6 id="file-access-modes">File Access Modes</h6>

<p>Similar to Python's built-in open(), supports the following modes:</p>

<p>Basic modes:</p>

<ul>
<li>'r'  : Read-only. Blob must exist. Position starts at beginning.</li>
<li>'w'  : Write-only. Creates new or truncates existing. Position at start. <strong>If the blob already exists,
truncation will ignore any other parameters supplied and rely on existing configuration.</strong></li>
<li>'a'  : Append-only. Blob must exist. Position starts at end.
All writes go to end regardless of seek position.</li>
</ul>

<p>Update modes (with '+'):</p>

<ul>
<li>'r+' : Read and write. Blob must exist. Position at start.
Can overwrite existing data or extend at end.</li>
<li>'w+' : Read and write. Creates new or truncates existing. Position at start.</li>
<li>'a+' : Read and append. Blob must exist. Position at end.
Reads allowed anywhere, writes always append to end.</li>
</ul>

<h6 id="data-type-and-shape">Data Type and Shape</h6>

<p>All tensors in a blob must have the same dtype and shape. These are
specified when creating a new blob (modes 'w', 'w+') and stored in
the configuration file. When opening existing blobs, dtype and shape
are loaded automatically.</p>

<p>Supported dtypes: "float32", "float64", "int32", "int64", "bool", etc.
Can also use torch.dtype objects like torch.float32.</p>

<p>Shape can be:</p>

<ul>
<li>Single integer: shape=10 creates 1D tensors of shape (10,)</li>
<li>Tuple: shape=(3, 224, 224) creates 3D tensors</li>
</ul>
</div>


                            </div>
                            <div id="TensorBlob.unlink" class="classattr">
                                        <input id="TensorBlob.unlink-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">unlink</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">filename</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="TensorBlob.unlink-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.unlink"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.unlink-231"><a href="#TensorBlob.unlink-231"><span class="linenos">231</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob.unlink-232"><a href="#TensorBlob.unlink-232"><span class="linenos">232</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">unlink</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
</span><span id="TensorBlob.unlink-233"><a href="#TensorBlob.unlink-233"><span class="linenos">233</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>
</span><span id="TensorBlob.unlink-234"><a href="#TensorBlob.unlink-234"><span class="linenos">234</span></a>        <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TensorBlob.unlink-235"><a href="#TensorBlob.unlink-235"><span class="linenos">235</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="TensorBlob.unlink-236"><a href="#TensorBlob.unlink-236"><span class="linenos">236</span></a>                <span class="k">with</span> <span class="bp">cls</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">_</span><span class="p">:</span>
</span><span id="TensorBlob.unlink-237"><a href="#TensorBlob.unlink-237"><span class="linenos">237</span></a>                    <span class="k">pass</span>
</span><span id="TensorBlob.unlink-238"><a href="#TensorBlob.unlink-238"><span class="linenos">238</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">filename</span> <span class="o">/</span> <span class="bp">cls</span><span class="o">.</span><span class="n">config_name</span><span class="p">)</span>
</span><span id="TensorBlob.unlink-239"><a href="#TensorBlob.unlink-239"><span class="linenos">239</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">filename</span> <span class="o">/</span> <span class="bp">cls</span><span class="o">.</span><span class="n">status_name</span><span class="p">)</span>
</span><span id="TensorBlob.unlink-240"><a href="#TensorBlob.unlink-240"><span class="linenos">240</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">rmdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">fspath</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span>
</span><span id="TensorBlob.unlink-241"><a href="#TensorBlob.unlink-241"><span class="linenos">241</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
</span><span id="TensorBlob.unlink-242"><a href="#TensorBlob.unlink-242"><span class="linenos">242</span></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Failed to unlink blob at </span><span class="si">%r</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">exc</span><span class="p">))</span>
</span><span id="TensorBlob.unlink-243"><a href="#TensorBlob.unlink-243"><span class="linenos">243</span></a>                <span class="k">return</span> <span class="kc">False</span>
</span><span id="TensorBlob.unlink-244"><a href="#TensorBlob.unlink-244"><span class="linenos">244</span></a>        <span class="k">return</span> <span class="kc">True</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.apply_param_hooks" class="classattr">
                                        <input id="TensorBlob.apply_param_hooks-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">apply_param_hooks</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">d</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="TensorBlob.apply_param_hooks-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.apply_param_hooks"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.apply_param_hooks-246"><a href="#TensorBlob.apply_param_hooks-246"><span class="linenos">246</span></a>    <span class="nd">@classmethod</span>
</span><span id="TensorBlob.apply_param_hooks-247"><a href="#TensorBlob.apply_param_hooks-247"><span class="linenos">247</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">apply_param_hooks</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
</span><span id="TensorBlob.apply_param_hooks-248"><a href="#TensorBlob.apply_param_hooks-248"><span class="linenos">248</span></a>        <span class="n">d</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">])</span>
</span><span id="TensorBlob.apply_param_hooks-249"><a href="#TensorBlob.apply_param_hooks-249"><span class="linenos">249</span></a>        <span class="k">return</span> <span class="n">d</span>
</span></pre></div>


            <div class="docstring"><p>Apply post-processing hooks to the JSON dictionary.</p>

<p><code>orjson.loads</code> only decode configs to primitive types, which may not be directly
consumable by the class initializer. For instance, a <code>dataclass</code> object will be
loaded as a dictionary. Therefore, this method is intended to be overridden by the
subclass to perform additional post-processing on the loaded config dictionary.</p>

<p>Note that, it is highly discouraged to abuse this method to deserialize complex objects
and one should consider using <code>runtime_kwargs</code> argument of <code><a href="#TensorBlob.from_config">from_config</a></code> instead,
to explicitly pass the complex objects to the class initializer.</p>

<p>By default, this method returns the input dictionary unchanged.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>jdict</strong> (dict[str, Any]):
The config dictionary after deserialization.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>dict[str, Any]</strong>: The config dictionary after post-processing.</li>
</ul>
</div>


                            </div>
                            <div id="TensorBlob.filename" class="classattr">
                                <div class="attr variable">
            <span class="name">filename</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.filename"></a>
    
    

                            </div>
                            <div id="TensorBlob.dtype" class="classattr">
                                <div class="attr variable">
            <span class="name">dtype</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.dtype"></a>
    
    

                            </div>
                            <div id="TensorBlob.shape" class="classattr">
                                <div class="attr variable">
            <span class="name">shape</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.shape"></a>
    
    

                            </div>
                            <div id="TensorBlob.block_size" class="classattr">
                                <div class="attr variable">
            <span class="name">block_size</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.block_size"></a>
    
    

                            </div>
                            <div id="TensorBlob.mode" class="classattr">
                                <div class="attr variable">
            <span class="name">mode</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.mode"></a>
    
    

                            </div>
                            <div id="TensorBlob.max_cached_blocks" class="classattr">
                                <div class="attr variable">
            <span class="name">max_cached_blocks</span>

        
    </div>
    <a class="headerlink" href="#TensorBlob.max_cached_blocks"></a>
    
    

                            </div>
                            <div id="TensorBlob.configpath" class="classattr">
                                        <input id="TensorBlob.configpath-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">configpath</span><span class="annotation">: str</span>

                <label class="view-source-button" for="TensorBlob.configpath-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.configpath"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.configpath-300"><a href="#TensorBlob.configpath-300"><span class="linenos">300</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob.configpath-301"><a href="#TensorBlob.configpath-301"><span class="linenos">301</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">configpath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="TensorBlob.configpath-302"><a href="#TensorBlob.configpath-302"><span class="linenos">302</span></a>        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config_name</span><span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.statuspath" class="classattr">
                                        <input id="TensorBlob.statuspath-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">statuspath</span><span class="annotation">: str</span>

                <label class="view-source-button" for="TensorBlob.statuspath-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.statuspath"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.statuspath-304"><a href="#TensorBlob.statuspath-304"><span class="linenos">304</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob.statuspath-305"><a href="#TensorBlob.statuspath-305"><span class="linenos">305</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">statuspath</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="TensorBlob.statuspath-306"><a href="#TensorBlob.statuspath-306"><span class="linenos">306</span></a>        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_name</span><span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.closed" class="classattr">
                                        <input id="TensorBlob.closed-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">closed</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="TensorBlob.closed-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.closed"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.closed-308"><a href="#TensorBlob.closed-308"><span class="linenos">308</span></a>    <span class="nd">@property</span>
</span><span id="TensorBlob.closed-309"><a href="#TensorBlob.closed-309"><span class="linenos">309</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">closed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="TensorBlob.closed-310"><a href="#TensorBlob.closed-310"><span class="linenos">310</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.tell" class="classattr">
                                        <input id="TensorBlob.tell-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">tell</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="nb">int</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.tell-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.tell"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.tell-434"><a href="#TensorBlob.tell-434"><span class="linenos">434</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">tell</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob.tell-435"><a href="#TensorBlob.tell-435"><span class="linenos">435</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob.tell-436"><a href="#TensorBlob.tell-436"><span class="linenos">436</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.seek" class="classattr">
                                        <input id="TensorBlob.seek-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">seek</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>, </span><span class="param"><span class="n">whence</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="nb">int</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.seek-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.seek"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.seek-438"><a href="#TensorBlob.seek-438"><span class="linenos">438</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">seek</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">whence</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_SET</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob.seek-439"><a href="#TensorBlob.seek-439"><span class="linenos">439</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkclosed</span><span class="p">()</span>
</span><span id="TensorBlob.seek-440"><a href="#TensorBlob.seek-440"><span class="linenos">440</span></a>        <span class="k">match</span> <span class="n">whence</span><span class="p">:</span>
</span><span id="TensorBlob.seek-441"><a href="#TensorBlob.seek-441"><span class="linenos">441</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_SET</span><span class="p">:</span>
</span><span id="TensorBlob.seek-442"><a href="#TensorBlob.seek-442"><span class="linenos">442</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="n">pos</span>
</span><span id="TensorBlob.seek-443"><a href="#TensorBlob.seek-443"><span class="linenos">443</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_CUR</span><span class="p">:</span>
</span><span id="TensorBlob.seek-444"><a href="#TensorBlob.seek-444"><span class="linenos">444</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+</span> <span class="n">pos</span>
</span><span id="TensorBlob.seek-445"><a href="#TensorBlob.seek-445"><span class="linenos">445</span></a>            <span class="k">case</span> <span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">:</span>
</span><span id="TensorBlob.seek-446"><a href="#TensorBlob.seek-446"><span class="linenos">446</span></a>                <span class="n">_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="n">pos</span>
</span><span id="TensorBlob.seek-447"><a href="#TensorBlob.seek-447"><span class="linenos">447</span></a>            <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="TensorBlob.seek-448"><a href="#TensorBlob.seek-448"><span class="linenos">448</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid whence: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">whence</span><span class="p">)</span>
</span><span id="TensorBlob.seek-449"><a href="#TensorBlob.seek-449"><span class="linenos">449</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">_pos</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="TensorBlob.seek-450"><a href="#TensorBlob.seek-450"><span class="linenos">450</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.close" class="classattr">
                                        <input id="TensorBlob.close-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">close</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.close-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.close"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.close-452"><a href="#TensorBlob.close-452"><span class="linenos">452</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob.close-453"><a href="#TensorBlob.close-453"><span class="linenos">453</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_wr</span><span class="p">:</span>
</span><span id="TensorBlob.close-454"><a href="#TensorBlob.close-454"><span class="linenos">454</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span><span id="TensorBlob.close-455"><a href="#TensorBlob.close-455"><span class="linenos">455</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">True</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.flush" class="classattr">
                                        <input id="TensorBlob.flush-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">flush</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.flush-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.flush"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.flush-457"><a href="#TensorBlob.flush-457"><span class="linenos">457</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob.flush-458"><a href="#TensorBlob.flush-458"><span class="linenos">458</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob.flush-459"><a href="#TensorBlob.flush-459"><span class="linenos">459</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statuspath</span><span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.read" class="classattr">
                                        <input id="TensorBlob.read-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">read</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.read-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.read"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.read-461"><a href="#TensorBlob.read-461"><span class="linenos">461</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="TensorBlob.read-462"><a href="#TensorBlob.read-462"><span class="linenos">462</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkreadable</span><span class="p">()</span>
</span><span id="TensorBlob.read-463"><a href="#TensorBlob.read-463"><span class="linenos">463</span></a>        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+</span> <span class="p">(</span><span class="n">size</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob.read-464"><a href="#TensorBlob.read-464"><span class="linenos">464</span></a>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="p">:</span> <span class="n">end</span><span class="p">]</span>
</span><span id="TensorBlob.read-465"><a href="#TensorBlob.read-465"><span class="linenos">465</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
</span><span id="TensorBlob.read-466"><a href="#TensorBlob.read-466"><span class="linenos">466</span></a>        <span class="k">return</span> <span class="n">ret</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.write" class="classattr">
                                        <input id="TensorBlob.write-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">write</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">ts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></span><span class="return-annotation">) -> <span class="nb">int</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.write-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.write"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.write-468"><a href="#TensorBlob.write-468"><span class="linenos">468</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob.write-469"><a href="#TensorBlob.write-469"><span class="linenos">469</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob.write-470"><a href="#TensorBlob.write-470"><span class="linenos">470</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m_ap</span><span class="p">:</span>
</span><span id="TensorBlob.write-471"><a href="#TensorBlob.write-471"><span class="linenos">471</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob.write-472"><a href="#TensorBlob.write-472"><span class="linenos">472</span></a>        <span class="n">ts</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="TensorBlob.write-473"><a href="#TensorBlob.write-473"><span class="linenos">473</span></a>        <span class="n">nt</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="TensorBlob.write-474"><a href="#TensorBlob.write-474"><span class="linenos">474</span></a>
</span><span id="TensorBlob.write-475"><a href="#TensorBlob.write-475"><span class="linenos">475</span></a>        <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="TensorBlob.write-476"><a href="#TensorBlob.write-476"><span class="linenos">476</span></a>        <span class="k">while</span> <span class="n">cnt</span> <span class="o">&lt;</span> <span class="n">nt</span><span class="p">:</span>
</span><span id="TensorBlob.write-477"><a href="#TensorBlob.write-477"><span class="linenos">477</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_isfull</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="TensorBlob.write-478"><a href="#TensorBlob.write-478"><span class="linenos">478</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_addblock</span><span class="p">()</span>
</span><span id="TensorBlob.write-479"><a href="#TensorBlob.write-479"><span class="linenos">479</span></a>            <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob.write-480"><a href="#TensorBlob.write-480"><span class="linenos">480</span></a>            <span class="n">incr</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">-</span> <span class="n">o</span><span class="p">,</span> <span class="n">nt</span> <span class="o">-</span> <span class="n">cnt</span><span class="p">)</span>
</span><span id="TensorBlob.write-481"><a href="#TensorBlob.write-481"><span class="linenos">481</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_getblock</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="n">o</span> <span class="p">:</span> <span class="n">o</span> <span class="o">+</span> <span class="n">incr</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts</span><span class="p">[</span><span class="n">cnt</span> <span class="p">:</span> <span class="n">cnt</span> <span class="o">+</span> <span class="n">incr</span><span class="p">]</span>
</span><span id="TensorBlob.write-482"><a href="#TensorBlob.write-482"><span class="linenos">482</span></a>
</span><span id="TensorBlob.write-483"><a href="#TensorBlob.write-483"><span class="linenos">483</span></a>            <span class="c1"># Update status length for new tensors exceeding the original range only, because</span>
</span><span id="TensorBlob.write-484"><a href="#TensorBlob.write-484"><span class="linenos">484</span></a>            <span class="c1"># the cursor may not always be the at EOF and the number of tensors written could</span>
</span><span id="TensorBlob.write-485"><a href="#TensorBlob.write-485"><span class="linenos">485</span></a>            <span class="c1"># be smaller than change in length</span>
</span><span id="TensorBlob.write-486"><a href="#TensorBlob.write-486"><span class="linenos">486</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">+=</span> <span class="n">incr</span>
</span><span id="TensorBlob.write-487"><a href="#TensorBlob.write-487"><span class="linenos">487</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">+=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
</span><span id="TensorBlob.write-488"><a href="#TensorBlob.write-488"><span class="linenos">488</span></a>
</span><span id="TensorBlob.write-489"><a href="#TensorBlob.write-489"><span class="linenos">489</span></a>            <span class="n">cnt</span> <span class="o">+=</span> <span class="n">incr</span>
</span><span id="TensorBlob.write-490"><a href="#TensorBlob.write-490"><span class="linenos">490</span></a>
</span><span id="TensorBlob.write-491"><a href="#TensorBlob.write-491"><span class="linenos">491</span></a>        <span class="k">assert</span> <span class="n">cnt</span> <span class="o">==</span> <span class="n">nt</span><span class="p">,</span> <span class="s2">&quot;Write incomplete: wrote </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2"> tensors!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cnt</span><span class="p">,</span> <span class="n">nt</span><span class="p">)</span>
</span><span id="TensorBlob.write-492"><a href="#TensorBlob.write-492"><span class="linenos">492</span></a>        <span class="k">return</span> <span class="n">cnt</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.truncate" class="classattr">
                                        <input id="TensorBlob.truncate-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">truncate</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="nb">int</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.truncate-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.truncate"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.truncate-494"><a href="#TensorBlob.truncate-494"><span class="linenos">494</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">truncate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="TensorBlob.truncate-495"><a href="#TensorBlob.truncate-495"><span class="linenos">495</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob.truncate-496"><a href="#TensorBlob.truncate-496"><span class="linenos">496</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">pos</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">())</span>
</span><span id="TensorBlob.truncate-497"><a href="#TensorBlob.truncate-497"><span class="linenos">497</span></a>        <span class="n">brk</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span><span id="TensorBlob.truncate-498"><a href="#TensorBlob.truncate-498"><span class="linenos">498</span></a>        <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[</span><span class="n">brk</span><span class="p">:]:</span>
</span><span id="TensorBlob.truncate-499"><a href="#TensorBlob.truncate-499"><span class="linenos">499</span></a>            <span class="k">if</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">:</span>
</span><span id="TensorBlob.truncate-500"><a href="#TensorBlob.truncate-500"><span class="linenos">500</span></a>                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">bd</span><span class="p">]</span>
</span><span id="TensorBlob.truncate-501"><a href="#TensorBlob.truncate-501"><span class="linenos">501</span></a>            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
</span><span id="TensorBlob.truncate-502"><a href="#TensorBlob.truncate-502"><span class="linenos">502</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[:</span><span class="n">brk</span><span class="p">]</span>
</span><span id="TensorBlob.truncate-503"><a href="#TensorBlob.truncate-503"><span class="linenos">503</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span><span id="TensorBlob.truncate-504"><a href="#TensorBlob.truncate-504"><span class="linenos">504</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span><span id="TensorBlob.truncate-505"><a href="#TensorBlob.truncate-505"><span class="linenos">505</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
</span></pre></div>


    

                            </div>
                            <div id="TensorBlob.extend" class="classattr">
                                        <input id="TensorBlob.extend-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">extend</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">other</span><span class="p">:</span> <span class="n"><a href="#TensorBlob">TensorBlob</a></span>,</span><span class="param">	<span class="n">maintain_order</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="TensorBlob.extend-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TensorBlob.extend"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TensorBlob.extend-507"><a href="#TensorBlob.extend-507"><span class="linenos">507</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">extend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">TensorBlob</span><span class="p">,</span> <span class="n">maintain_order</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TensorBlob.extend-508"><a href="#TensorBlob.extend-508"><span class="linenos">508</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="TensorBlob.extend-509"><a href="#TensorBlob.extend-509"><span class="linenos">509</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Blob data types and shapes must match to extend blobs!&quot;</span><span class="p">)</span>
</span><span id="TensorBlob.extend-510"><a href="#TensorBlob.extend-510"><span class="linenos">510</span></a>
</span><span id="TensorBlob.extend-511"><a href="#TensorBlob.extend-511"><span class="linenos">511</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_checkwritable</span><span class="p">()</span>
</span><span id="TensorBlob.extend-512"><a href="#TensorBlob.extend-512"><span class="linenos">512</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob.extend-513"><a href="#TensorBlob.extend-513"><span class="linenos">513</span></a>
</span><span id="TensorBlob.extend-514"><a href="#TensorBlob.extend-514"><span class="linenos">514</span></a>        <span class="c1"># TODO: Honestly this is a bit inefficient but I think this is rarely used.</span>
</span><span id="TensorBlob.extend-515"><a href="#TensorBlob.extend-515"><span class="linenos">515</span></a>        <span class="k">if</span> <span class="n">maintain_order</span><span class="p">:</span>
</span><span id="TensorBlob.extend-516"><a href="#TensorBlob.extend-516"><span class="linenos">516</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)):</span>
</span><span id="TensorBlob.extend-517"><a href="#TensorBlob.extend-517"><span class="linenos">517</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">other</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="TensorBlob.extend-518"><a href="#TensorBlob.extend-518"><span class="linenos">518</span></a>            <span class="k">return</span>
</span><span id="TensorBlob.extend-519"><a href="#TensorBlob.extend-519"><span class="linenos">519</span></a>
</span><span id="TensorBlob.extend-520"><a href="#TensorBlob.extend-520"><span class="linenos">520</span></a>        <span class="c1"># If order is not important, we can simply copy over the complete blocks from</span>
</span><span id="TensorBlob.extend-521"><a href="#TensorBlob.extend-521"><span class="linenos">521</span></a>        <span class="c1"># the other blob and merge incomplete blocks.</span>
</span><span id="TensorBlob.extend-522"><a href="#TensorBlob.extend-522"><span class="linenos">522</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span><span class="p">:</span>
</span><span id="TensorBlob.extend-523"><a href="#TensorBlob.extend-523"><span class="linenos">523</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="TensorBlob.extend-524"><a href="#TensorBlob.extend-524"><span class="linenos">524</span></a>                <span class="s2">&quot;Block sizes must match to extend blobs in non-order-preserving mode!&quot;</span>
</span><span id="TensorBlob.extend-525"><a href="#TensorBlob.extend-525"><span class="linenos">525</span></a>            <span class="p">)</span>
</span><span id="TensorBlob.extend-526"><a href="#TensorBlob.extend-526"><span class="linenos">526</span></a>
</span><span id="TensorBlob.extend-527"><a href="#TensorBlob.extend-527"><span class="linenos">527</span></a>        <span class="n">comb</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="TensorBlob.extend-528"><a href="#TensorBlob.extend-528"><span class="linenos">528</span></a>        <span class="n">sbrk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob.extend-529"><a href="#TensorBlob.extend-529"><span class="linenos">529</span></a>        <span class="k">if</span> <span class="n">sbrk</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="TensorBlob.extend-530"><a href="#TensorBlob.extend-530"><span class="linenos">530</span></a>            <span class="n">comb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">sbrk</span><span class="p">:])</span>
</span><span id="TensorBlob.extend-531"><a href="#TensorBlob.extend-531"><span class="linenos">531</span></a>        <span class="n">obrk</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="o">//</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob.extend-532"><a href="#TensorBlob.extend-532"><span class="linenos">532</span></a>        <span class="k">if</span> <span class="n">obrk</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">):</span>
</span><span id="TensorBlob.extend-533"><a href="#TensorBlob.extend-533"><span class="linenos">533</span></a>            <span class="n">comb</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">other</span><span class="p">[</span><span class="n">obrk</span><span class="p">:])</span>
</span><span id="TensorBlob.extend-534"><a href="#TensorBlob.extend-534"><span class="linenos">534</span></a>
</span><span id="TensorBlob.extend-535"><a href="#TensorBlob.extend-535"><span class="linenos">535</span></a>        <span class="c1"># TODO: We are directly accessing internal data structures of the other blob here.</span>
</span><span id="TensorBlob.extend-536"><a href="#TensorBlob.extend-536"><span class="linenos">536</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">truncate</span><span class="p">(</span><span class="n">sbrk</span><span class="p">)</span>
</span><span id="TensorBlob.extend-537"><a href="#TensorBlob.extend-537"><span class="linenos">537</span></a>        <span class="k">for</span> <span class="n">obd</span> <span class="ow">in</span> <span class="n">other</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="o">//</span> <span class="n">other</span><span class="o">.</span><span class="n">block_size</span><span class="p">]:</span>
</span><span id="TensorBlob.extend-538"><a href="#TensorBlob.extend-538"><span class="linenos">538</span></a>            <span class="n">sbd</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
</span><span id="TensorBlob.extend-539"><a href="#TensorBlob.extend-539"><span class="linenos">539</span></a>            <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span>
</span><span id="TensorBlob.extend-540"><a href="#TensorBlob.extend-540"><span class="linenos">540</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">obd</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">sbd</span><span class="p">)</span>
</span><span id="TensorBlob.extend-541"><a href="#TensorBlob.extend-541"><span class="linenos">541</span></a>            <span class="p">)</span>
</span><span id="TensorBlob.extend-542"><a href="#TensorBlob.extend-542"><span class="linenos">542</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">bds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sbd</span><span class="p">)</span>
</span><span id="TensorBlob.extend-543"><a href="#TensorBlob.extend-543"><span class="linenos">543</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_status</span><span class="o">.</span><span class="n">len</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>
</span><span id="TensorBlob.extend-544"><a href="#TensorBlob.extend-544"><span class="linenos">544</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_memmap</span><span class="p">[</span><span class="n">sbd</span><span class="p">]</span> <span class="o">=</span> <span class="n">MemoryMappedTensor</span><span class="o">.</span><span class="n">from_filename</span><span class="p">(</span>
</span><span id="TensorBlob.extend-545"><a href="#TensorBlob.extend-545"><span class="linenos">545</span></a>                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">sbd</span><span class="p">),</span>
</span><span id="TensorBlob.extend-546"><a href="#TensorBlob.extend-546"><span class="linenos">546</span></a>                <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
</span><span id="TensorBlob.extend-547"><a href="#TensorBlob.extend-547"><span class="linenos">547</span></a>                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
</span><span id="TensorBlob.extend-548"><a href="#TensorBlob.extend-548"><span class="linenos">548</span></a>            <span class="p">)</span>
</span><span id="TensorBlob.extend-549"><a href="#TensorBlob.extend-549"><span class="linenos">549</span></a>
</span><span id="TensorBlob.extend-550"><a href="#TensorBlob.extend-550"><span class="linenos">550</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">whence</span><span class="o">=</span><span class="n">io</span><span class="o">.</span><span class="n">SEEK_END</span><span class="p">)</span>
</span><span id="TensorBlob.extend-551"><a href="#TensorBlob.extend-551"><span class="linenos">551</span></a>        <span class="k">if</span> <span class="n">comb</span><span class="p">:</span>
</span><span id="TensorBlob.extend-552"><a href="#TensorBlob.extend-552"><span class="linenos">552</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">comb</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="TensorBlob.extend-553"><a href="#TensorBlob.extend-553"><span class="linenos">553</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span></pre></div>


    

                            </div>
                </section>
    </main>
</body>
</html>